{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = Path.cwd()\n",
    "output = project / \"output\"\n",
    "output_data = output / \"data\"\n",
    "input = project / \"input\"\n",
    "figures = project / \"figures\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_butterworth(discharge, buff=20, dts=25, N=5):\n",
    "    \"\"\"apply butterworth filter to remove tidal influence from data\n",
    "    \n",
    "    input:\n",
    "    discharge = discharge dataframe\n",
    "    dts       = sampling interval in minutes\n",
    "    N         = filter order\n",
    "    \n",
    "    returns:\n",
    "    filtered dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    # parameters\n",
    "    crit_freq = 1/(((24.8412 + buff)*60*60))  # lundar day in hours to Hz\n",
    "    fs = 1/(dts*60)  # sampling frequency\n",
    "    \n",
    "    b, a = signal.butter(N, crit_freq, btype='lowpass', fs=fs)\n",
    "\n",
    "    filtered = discharge.apply(lambda x: signal.filtfilt(b, a, x))\n",
    "    filtered.columns = ['discharge_cms_Butterworth_filtered']\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "def apply_godin(discharge):\n",
    "    \"\"\"apply Godin filter to remove tidal influence from data\n",
    "    \n",
    "    input:\n",
    "    discharge = discharge dataframe\n",
    "    \n",
    "    returns:\n",
    "    filtered dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    # parameters\n",
    "    # Godin filter (USGS standard)\n",
    "    godin = discharge.resample('1H').mean().interpolate(method='time').rolling(\n",
    "        window=24, center=True).mean().rolling(\n",
    "        window=25, center=True).mean().rolling(\n",
    "        window=25, center=True).mean()\n",
    "    godin.columns = ['discharge_cms_Godin_filtered']\n",
    "    \n",
    "    return godin\n",
    "\n",
    "def download_nwis_data(\n",
    "    site_name, site_no, begin_date, end_date, data_code=60, skiprows=28\n",
    "):\n",
    "    \"\"\"download data from https://nwis.waterdata.usge and outputs as dataframe\n",
    "\n",
    "    inputs:\n",
    "    site_name = user specified name for site\n",
    "    site_no = USGS site number code\n",
    "    begin_date = first day in timeseries (YYYY-MM-dd)\n",
    "    end_date = last day in timeseries (YYYY-MM-dd)\n",
    "    skiprows = number of header rows to skip (default=28)\n",
    "\n",
    "    return = discharge (pandas DataFrame)\n",
    "    \"\"\"\n",
    "\n",
    "    # output file and request\n",
    "    out_fn = output_data / f\"{site_name}_{site_no}_{begin_date}_{end_date}.txt\"\n",
    "    request = f\"https://nwis.waterdata.usgs.gov/usa/nwis/uv/?cb_{data_code:05d}=on&format=rdb&site_no={site_no}&period=&begin_date={begin_date}&end_date={end_date}\"\n",
    "\n",
    "    # get data\n",
    "    txt, http = urllib.request.urlretrieve(request, out_fn)\n",
    "    \n",
    "    # Pandas\n",
    "    try:\n",
    "        data = pd.read_csv(\n",
    "            txt,\n",
    "            sep=\"\\s+\",\n",
    "            skiprows=skiprows,\n",
    "            usecols=[2, 3, 5],\n",
    "            parse_dates={\"datetime_CST\": [0, 1]},\n",
    "            header=0,\n",
    "            index_col=0,\n",
    "            names=[\"date\", \"time\", \"discharge\"],\n",
    "        )\n",
    "    except:\n",
    "        print(\"Problem with parsing text \")\n",
    "        os.remove(txt)\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        data.index = (\n",
    "            data.index.tz_localize(\"America/Chicago\", ambiguous=True)\n",
    "            .tz_convert(\"UTC\")\n",
    "            .tz_localize(None)\n",
    "        )\n",
    "    except AttributeError as e:\n",
    "        print(\"Problem converting datetime to UTC. Check data\")\n",
    "        os.remove(txt)\n",
    "        return None\n",
    "\n",
    "    data.to_csv(\n",
    "        output_data / f\"{site_name}_{begin_date}.csv\",\n",
    "        sep=\"\\t\",\n",
    "        header=[\"val\"],\n",
    "        index_label=[\"datetime_UTC\"],\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in site list\n",
    "site_list_fn = input / \"site_list_MS_Sound_area.csv\"\n",
    "site_list = pd.read_csv(site_list_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download\n",
    "begin_date = \"2018-01-01\"\n",
    "end_date = \"2019-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_code = 480\n",
    "df = pd.DataFrame(columns=[\"site_no\", \"site_name\", \"lat\", \"lon\"])\n",
    "\n",
    "for row in site_list.itertuples():\n",
    "    url = row._7\n",
    "    site_no = url.split(\"=\")[-1]\n",
    "    site_name = row._2\n",
    "    lat = row._6\n",
    "    lon = row._5\n",
    "    data = download_nwis_data(\n",
    "        site_name, site_no, begin_date, end_date, data_code=data_code\n",
    "    )\n",
    "    if data is not None:\n",
    "        df = df.append(\n",
    "            {\"site_no\": site_no, \"site_name\": site_name, \"lat\": lat, \"lon\": lon},\n",
    "            ignore_index=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(\n",
    "    df, geometry=gpd.points_from_xy(df[\"lon\"], df[\"lat\"]), crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf.to_file(output / \"salinity_stations_2018.shp\")\n",
    "df[[\"lon\", \"lat\", \"site_no\"]].to_csv(\n",
    "    output / \"salinity_stations_2018.xyn\", sep=\"\\t\", index=False, header=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
