{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xarray as xr\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "\n",
    "hv.extension(\"bokeh\")\n",
    "\n",
    "from bokeh.io import curdoc, output_notebook\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.themes import built_in_themes\n",
    "\n",
    "output_notebook()\n",
    "curdoc().theme = \"light_minimal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots\n",
    "plt.style.use(\"seaborn-talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d3d = Path(\"/mnt/c/Users/rdchlclj/Projects/MR_D3D_model/Delft3D\")\n",
    "project = Path.cwd()\n",
    "output = project / \"output\"\n",
    "input = project / \"input\"\n",
    "output_data = output / \"data\"\n",
    "figures = project / \"figures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation stations\n",
    "begin_date = \"2018-01-01\"\n",
    "end_date = \"2018-11-23\"\n",
    "model_input = d3d / \"MS_River_plume.dsproj_data/regional/input\"\n",
    "station_list = pd.read_csv(\n",
    "    model_input / \"salinity_stations_obs.xyn\",\n",
    "    sep=\"\\s+\",\n",
    "    header=None,\n",
    "    names=[\"lon\", \"lat\", \"station_id\"],\n",
    ")\n",
    "\n",
    "station_list[\"station_id\"] = station_list[\"station_id\"].apply(lambda s: s.strip(\"'\"))\n",
    "station_list[\"station_code\"] = station_list[\"station_id\"].apply(lambda s: s.encode())\n",
    "station_list = station_list.set_index(station_list.station_code).drop(\n",
    "    \"station_code\", axis=1\n",
    ")\n",
    "sal_stations = list(station_list.index)\n",
    "\n",
    "spread_sheet = pd.read_excel(\n",
    "    input / \"USGS_salinity_stations_2018.xls\", dtype={\"station_id\": str}\n",
    ")\n",
    "spread_sheet[\"station_code\"] = spread_sheet[\"station_id\"].apply(lambda s: s.encode())\n",
    "nicknames = pd.DataFrame(data=spread_sheet[\"nickname\"].values, index=spread_sheet[\"station_code\"], columns=[\"nickname\"])\n",
    "station_list = station_list.join(nicknames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model input/output\n",
    "model = \"p03\"\n",
    "model_output = Path(\"/mnt/g/MR_D3D_Model/Delft3D/models/prod_2018/p03_10sig_2018prod\")\n",
    "his_fn = model_output / f\"{model}_merged_his.nc\"\n",
    "variables = [\"waterlevel\", \"bedlevel\", \"waterdepth\", \"salinity\"]\n",
    "calib_his = (\n",
    "    xr.open_dataset(his_fn)[variables]\n",
    "    .swap_dims({\"stations\": \"station_name\"})\n",
    "    .sel(station_name=sal_stations)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model input/output\n",
    "model = \"f07\"\n",
    "model_output = Path(\"/mnt/g/MR_D3D_Model/Delft3D/models/f07_10sig_davg_sal_rst/output\")\n",
    "his_fn = model_output / f\"{model}_10sig_davg_sal_rst_his.nc\"\n",
    "variables = [\"waterlevel\", \"bedlevel\", \"waterdepth\", \"salinity\"]\n",
    "uncalib_his = (\n",
    "    xr.open_dataset(his_fn)[variables]\n",
    "    .swap_dims({\"stations\": \"station_name\"})\n",
    "    .sel(station_name=sal_stations[:-5])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_butterworth(discharge, buff=20, dts=25, N=5):\n",
    "    \"\"\"apply butterworth filter to remove tidal influence from data\n",
    "\n",
    "    input:\n",
    "    discharge = discharge dataframe\n",
    "    dts       = sampling interval in minutes\n",
    "    N         = filter order\n",
    "\n",
    "    returns:\n",
    "    filtered dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    # parameters\n",
    "    crit_freq = 1 / (((24.8412 + buff) * 60 * 60))  # lundar day in hours to Hz\n",
    "    fs = 1 / (dts * 60)  # sampling frequency\n",
    "\n",
    "    b, a = signal.butter(N, crit_freq, btype=\"lowpass\", fs=fs)\n",
    "\n",
    "    filtered = discharge.apply(lambda x: signal.filtfilt(b, a, x))\n",
    "    filtered.columns = [\"discharge_cms_Butterworth_filtered\"]\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def apply_godin(discharge):\n",
    "    \"\"\"apply Godin filter to remove tidal influence from data\n",
    "\n",
    "    input:\n",
    "    discharge = discharge dataframe\n",
    "\n",
    "    returns:\n",
    "    filtered dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    # parameters\n",
    "    # Godin filter (USGS standard)\n",
    "    godin = (\n",
    "        discharge.resample(\"1H\")\n",
    "        .mean()\n",
    "        .interpolate(method=\"time\")\n",
    "        .rolling(window=24, center=True)\n",
    "        .mean()\n",
    "        .rolling(window=25, center=True)\n",
    "        .mean()\n",
    "        .rolling(window=25, center=True)\n",
    "        .mean()\n",
    "    )\n",
    "    godin.columns = [\"discharge_cms_Godin_filtered\"]\n",
    "\n",
    "    return godin\n",
    "\n",
    "\n",
    "def download_nwis_data(\n",
    "    site_name, site_no, begin_date, end_date, data_code=60, skiprows=28\n",
    "):\n",
    "    \"\"\"download data from https://nwis.waterdata.usge and outputs as dataframe\n",
    "\n",
    "    inputs:\n",
    "    site_name = user specified name for site\n",
    "    site_no = USGS site number code\n",
    "    begin_date = first day in timeseries (YYYY-MM-dd)\n",
    "    end_date = last day in timeseries (YYYY-MM-dd)\n",
    "    skiprows = number of header rows to skip (default=28)\n",
    "\n",
    "    return = discharge (pandas DataFrame)\n",
    "    \"\"\"\n",
    "\n",
    "    # output file and request\n",
    "    out_fn = output_data / f\"{site_name}_{site_no}_{begin_date}_{end_date}.txt\"\n",
    "    request = f\"https://nwis.waterdata.usgs.gov/usa/nwis/uv/?cb_{data_code:05d}=on&format=rdb&site_no={site_no}&period=&begin_date={begin_date}&end_date={end_date}\"\n",
    "\n",
    "    # get data\n",
    "    txt, http = urllib.request.urlretrieve(request, out_fn)\n",
    "\n",
    "    # Pandas\n",
    "    try:\n",
    "        data = pd.read_csv(\n",
    "            txt,\n",
    "            sep=\"\\s+\",\n",
    "            skiprows=skiprows,\n",
    "            usecols=[2, 3, 5],\n",
    "            parse_dates={\"datetime_CST\": [0, 1]},\n",
    "            header=0,\n",
    "            index_col=0,\n",
    "            names=[\"date\", \"time\", \"salinity_ppt\"],\n",
    "            na_values=[\"Eqp\", \"***\", \"--\", \"Dis\", \"Dry\", \"Ice\", \"Mnt\", \"Ssn\", \"ZFl\"],\n",
    "            dtype={\"salinity_ppt\": float}\n",
    "        )\n",
    "    except:\n",
    "        print(\"Problem with parsing text \")\n",
    "        os.remove(txt)\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        data.index = (\n",
    "            data.index.tz_localize(\"America/Chicago\", ambiguous=True)\n",
    "            .tz_convert(\"UTC\")\n",
    "            .tz_localize(None)\n",
    "        )\n",
    "    except AttributeError as e:\n",
    "        print(\"Problem converting datetime to UTC. Check data\")\n",
    "        os.remove(txt)\n",
    "        return None\n",
    "\n",
    "    data.to_csv(\n",
    "        output_data / f\"{site_name}_{begin_date}.csv\",\n",
    "        sep=\"\\t\",\n",
    "        header=[\"val\"],\n",
    "        index_label=[\"datetime_UTC\"],\n",
    "    )\n",
    "    return data\n",
    "\n",
    "def download_nwis_site_info(\n",
    "    site_name, site_no, skiprows=34\n",
    "):\n",
    "    \"\"\"download data from https://nwis.waterdata.usge and outputs as dataframe\n",
    "\n",
    "    inputs:\n",
    "    site_name = user specified name for site\n",
    "    site_no = USGS site number code\n",
    "    skiprows = number of header rows to skip (default=28)\n",
    "\n",
    "    return = site info\n",
    "    \"\"\"\n",
    "\n",
    "    # output file and request\n",
    "    out_fn = output_data / f\"{site_name}_{site_no}_site_information.txt\"\n",
    "    request = f\"https://waterdata.usgs.gov/nwis/site/?format=rdb&site_no={site_no}\"\n",
    "\n",
    "    # get data\n",
    "    txt, http = urllib.request.urlretrieve(request, out_fn)\n",
    "\n",
    "    # Pandas\n",
    "    try:\n",
    "        data = pd.read_csv(\n",
    "            txt,\n",
    "            sep=\"\\t\",\n",
    "            skiprows=skiprows,\n",
    "            usecols=[2, 9, 10],\n",
    "            header=0,\n",
    "            names=[\"site_name\", \"gage_alt_ft\", \"alt_datum\"],\n",
    "            na_values=[\"Eqp\", \"***\", \"--\", \"Dis\", \"Dry\", \"Ice\", \"Mnt\", \"Ssn\", \"ZFl\"],\n",
    "            dtype={\"salinity_ppt\": float}\n",
    "        )\n",
    "    except:\n",
    "        print(\"Problem with parsing text \")\n",
    "        os.remove(txt)\n",
    "        return None\n",
    "    \n",
    "    data[\"gage_alt_m\"] = data[\"gage_alt_ft\"] * 0.3048\n",
    "\n",
    "\n",
    "    data.to_csv(\n",
    "        output_data / f\"{site_name}_{begin_date}.csv\",\n",
    "        sep=\"\\t\"\n",
    "    )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"p03\"\n",
    "data_code = 480\n",
    "bird_foot_stations = [\n",
    "    \"Cow Bayou\",\n",
    "    \"Bay Gardene\",\n",
    "    \"Empire Waterway\",\n",
    "    \"Snake Island\",\n",
    "    \"Stone Island\",\n",
    "    \"Crooked Bayou\",\n",
    "]\n",
    "\n",
    "plot_stations = [\n",
    "    \"Stone Island\",\n",
    "    \"Empire Waterway\",\n",
    "    \"Gulfport\",\n",
    "    \"East Ship\",\n",
    "    \"Biloxi Bay\"\n",
    "]\n",
    "\n",
    "plot_stations = [\n",
    "    \"Graveline Bayou\",\n",
    "    \"Grand Pass\",\n",
    "    \"Gulfport\",\n",
    "    \"East Ship Island\",\n",
    "    \"Biloxi Bay\",\n",
    "]\n",
    "\n",
    "t0 = pd.to_datetime(\"2018-09-01\")\n",
    "tf = pd.to_datetime(\"2018-10-01\")\n",
    "\n",
    "c = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][2]\n",
    "c2 = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][0]\n",
    "for station in his.station_name.values:\n",
    "\n",
    "    # station = station.decode(\"utf-8\")\n",
    "    station_info = station_list.loc[station]\n",
    "    station_id = station_info[\"station_id\"]\n",
    "    station_no = station_info.name.decode()\n",
    "    nickname = station_info.nickname\n",
    "\n",
    "    if station_id[:4] == \"CRMS\":\n",
    "        continue\n",
    "\n",
    "    if nickname in set(plot_stations):\n",
    "        continue\n",
    "\n",
    "    obs_fn = output_data / f\"{station_id}_{begin_date}.csv\"\n",
    "\n",
    "    if not obs_fn.exists():\n",
    "        print(\"Data missing. Fetching from internet!\")\n",
    "        obs = download_nwis_data(\n",
    "            station_id, station_no, begin_date, end_date, data_code=data_code\n",
    "        )\n",
    "    else:\n",
    "        print(\"Data exists!\")\n",
    "        obs = pd.read_csv(obs_fn, sep=\"\\t\", index_col=[0], dtype={\"val\": float})\n",
    "\n",
    "    try:\n",
    "        if obs == None:\n",
    "            continue\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # get vertical position\n",
    "    station_details = download_nwis_site_info(nickname, station_no)\n",
    "    gage_z = station_details[\"gage_alt_m\"].values\n",
    "\n",
    "    # load model output\n",
    "    mod = his.sel(station_name=station)\n",
    "\n",
    "    mean_h = mod.where(mod.waterdepth != -999.0).waterdepth.mean(dim=\"time\").values\n",
    "\n",
    "    # get mean of center sigma layers to index entire series\n",
    "    mean_z = mod.zcoordinate_c.mean(dim=\"time\").values\n",
    "    gage_idx = np.argmin(np.abs(mean_z - gage_z))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    sal = mod[\"salinity\"].isel(laydim=gage_idx)\n",
    "\n",
    "    t = mod.time.values\n",
    "    ax.plot(t, sal, label=f\"computed salinity\", linewidth=1.75, zorder=100, color=c2)\n",
    "\n",
    "    obs_t = pd.to_datetime(obs.index)\n",
    "    obs_val = obs.values\n",
    "    ax.plot(\n",
    "        obs_t, obs_val, lw=1.25, color=c, label=\"observed salinity\",\n",
    "    )\n",
    "\n",
    "    ax.set_ylabel(\"Salinity (ppt)\")\n",
    "    ax.set_xlim(t[0], t[-1])\n",
    "    ax.set_title(f\"{nickname}\")\n",
    "    ax.legend()\n",
    "    #ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "    ax.grid()\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.set_ylim([0, ylim[1]])\n",
    "    ax.set_xlim(obs_t.min(), obs_t.max())\n",
    "\n",
    "    fn = figures / f\"{nickname}_{model}_salinity_comparison.png\"\n",
    "    fig.savefig(fn, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"f07\"\n",
    "data_code = 480\n",
    "bird_foot_stations = [\n",
    "    \"Cow Bayou\",\n",
    "    \"Bay Gardene\",\n",
    "    \"Empire Waterway\",\n",
    "    \"Snake Island\",\n",
    "    \"Stone Island\",\n",
    "    \"Crooked Bayou\",\n",
    "]\n",
    "\n",
    "c = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][2]\n",
    "c2 = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][0]\n",
    "for station in uncalib_his.station_name.values:\n",
    "\n",
    "    # station = station.decode(\"utf-8\")\n",
    "    station_info = station_list.loc[station]\n",
    "    station_id = station_info[\"station_id\"]\n",
    "    station_no = station_info.name.decode()\n",
    "    nickname = station_info.nickname\n",
    "\n",
    "    if station_id[:4] == \"CRMS\":\n",
    "        continue\n",
    "\n",
    "    # if nickname in set(bird_foot_stations):\n",
    "    #    continue\n",
    "\n",
    "    obs_fn = output_data / f\"{station_id}_{begin_date}.csv\"\n",
    "\n",
    "    if not obs_fn.exists():\n",
    "        print(\"Data missing. Fetching from internet!\")\n",
    "        obs = download_nwis_data(\n",
    "            station_id, station_no, begin_date, end_date, data_code=data_code\n",
    "        )\n",
    "    else:\n",
    "        print(\"Data exists!\")\n",
    "        obs = pd.read_csv(obs_fn, sep=\"\\t\", index_col=[0], dtype={\"val\": float})\n",
    "\n",
    "    try:\n",
    "        if obs == None:\n",
    "            continue\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # get vertical position\n",
    "    station_details = download_nwis_site_info(nickname, station_no)\n",
    "    gage_z = station_details[\"gage_alt_m\"].values\n",
    "\n",
    "    # load model output\n",
    "    mod = his.sel(station_name=station)\n",
    "\n",
    "    mean_h = mod.where(mod.waterdepth != -999.0).waterdepth.mean(dim=\"time\").values\n",
    "\n",
    "    # get mean of center sigma layers to index entire series\n",
    "    mean_z = mod.zcoordinate_c.mean(dim=\"time\").values\n",
    "    gage_idx = np.argmin(np.abs(mean_z - gage_z))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    sal = mod[\"salinity\"].isel(laydim=gage_idx)\n",
    "\n",
    "    t = mod.time.values\n",
    "    ax.plot(t, sal, label=f\"computed salinity\", linewidth=1.75, zorder=100, color=c2)\n",
    "\n",
    "    obs_t = pd.to_datetime(obs.index)\n",
    "    obs_val = obs.values\n",
    "    ax.plot(\n",
    "        obs_t, obs_val, lw=1.25, color=c, label=\"observed salinity\",\n",
    "    )\n",
    "\n",
    "    ax.set_ylabel(\"Salinity (ppt)\")\n",
    "    ax.set_xlim(t[0], t[-1])\n",
    "    ax.set_title(f\"{nickname}\")\n",
    "    ax.legend()\n",
    "    #ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "    ax.grid()\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.set_ylim([0, ylim[1]])\n",
    "    ax.set_xlim(obs_t.min(), obs_t.max())\n",
    "\n",
    "    fn = figures / f\"{nickname}_{model}_salinity_comparison.png\"\n",
    "    fig.savefig(fn, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"p03\"\n",
    "his = calib_his\n",
    "\n",
    "model = \"f07\"\n",
    "his = uncalib_his\n",
    "\n",
    "plot_stations = [\n",
    "    \"Stone Island\",\n",
    "    \"Empire Waterway\",\n",
    "    \"Gulfport\",\n",
    "    \"East Ship Island\",\n",
    "    \"Biloxi Bay\",\n",
    "]\n",
    "\n",
    "plot_stations = [\n",
    "    \"Graveline Bayou\",\n",
    "    \"Grand Pass\",\n",
    "    \"Gulfport\",\n",
    "    \"East Ship Island\",\n",
    "    \"Biloxi Bay\",\n",
    "]\n",
    "\n",
    "t0 = pd.to_datetime(\"2018-09-01\")\n",
    "tf = pd.to_datetime(\"2018-10-01\")\n",
    "\n",
    "c = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][2]\n",
    "c2 = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"][0]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(14, 14), nrows=5, sharex=True, sharey=True)\n",
    "\n",
    "i = 0\n",
    "for station in his.station_name.values:\n",
    "\n",
    "    # station = station.decode(\"utf-8\")\n",
    "    station_info = station_list.loc[station]\n",
    "    station_id = station_info[\"station_id\"]\n",
    "    station_no = station_info.name.decode()\n",
    "    nickname = station_info.nickname\n",
    "\n",
    "    if nickname not in set(plot_stations):\n",
    "        continue\n",
    "\n",
    "    ax = axes[i]\n",
    "    i += 1\n",
    "\n",
    "    obs_fn = output_data / f\"{station_id}_{begin_date}.csv\"\n",
    "    obs = pd.read_csv(obs_fn, sep=\"\\t\", index_col=[0], dtype={\"val\": float})\n",
    "\n",
    "    # get vertical position\n",
    "    station_details = download_nwis_site_info(nickname, station_no)\n",
    "    gage_z = station_details[\"gage_alt_m\"].values\n",
    "\n",
    "    # load model output\n",
    "    mod = his.sel(station_name=station)\n",
    "\n",
    "    # get mean of center sigma layers to index entire series\n",
    "    mean_z = mod.zcoordinate_c.mean(dim=\"time\").values\n",
    "    gage_idx = np.argmin(np.abs(mean_z - gage_z))\n",
    "\n",
    "    sal = mod[\"salinity\"].isel(laydim=gage_idx)\n",
    "\n",
    "    t = mod.time.values\n",
    "    ax.set_ylabel(\"Salinity (psu)\")\n",
    "\n",
    "    if nickname == \"Gulfport\" or nickname == \"East Ship Island\":\n",
    "        ypos = 0.1\n",
    "    else:\n",
    "        ypos = 0.8\n",
    "\n",
    "    ax.text(\n",
    "        x=0.025,\n",
    "        y=ypos,\n",
    "        s=f\"{nickname}\",\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=14,\n",
    "        bbox={\"facecolor\": \"w\", \"edgecolor\": \"b\"},\n",
    "    )\n",
    "\n",
    "    ax.set_xlim(t0, tf)\n",
    "    xticks = ax.get_xticks()\n",
    "    ax.set_xticks(xticks[:-1])\n",
    "\n",
    "    ax.tick_params(which=\"both\", axis=\"both\", direction=\"in\")\n",
    "\n",
    "    ax.grid(alpha=0.5, lw=0.5)\n",
    "    ax.set_ylim(0, 35)\n",
    "\n",
    "    if (model == \"f07\") and (nickname == \"Graveline Bayou\"):\n",
    "        continue\n",
    "\n",
    "    ax.plot(t, sal, label=f\"computed salinity\", linewidth=1.75, zorder=100, color=c2)\n",
    "\n",
    "    obs_t = pd.to_datetime(obs.index)\n",
    "    obs_val = obs.values\n",
    "    ax.plot(\n",
    "        obs_t, obs_val, lw=1.25, color=c, label=\"observed salinity\",\n",
    "    )\n",
    "    pass\n",
    "\n",
    "axes[0].legend()\n",
    "plt.subplots_adjust(hspace=0.1)\n",
    "\n",
    "fn = figures / f\"prod_{model}_salinity_comparison_multistation.png\"\n",
    "fig.savefig(fn, bbox_inches=\"tight\", dpi=500)\n",
    "\n",
    "fn = figures / f\"prod_{model}_salinity_comparison_multistation.svg\"\n",
    "fig.savefig(fn, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
