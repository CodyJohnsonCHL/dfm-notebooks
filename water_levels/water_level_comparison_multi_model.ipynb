{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import cartopy.crs as ccrs\n",
    "import pytide\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.extension(\"bokeh\")\n",
    "\n",
    "from bokeh.io import curdoc, output_notebook\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.themes import built_in_themes\n",
    "\n",
    "output_notebook()\n",
    "curdoc().theme = \"light_minimal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project files\n",
    "d3d = Path(\"/mnt/c/Users/rdchlclj/Projects/MR_D3D_model/Delft3D\")\n",
    "data = Path(\"/mnt/e/MS_River_plume\")\n",
    "project = d3d / \"tidal_constituent_boundary_conditions\"\n",
    "output = project / \"output\"\n",
    "figures = project / \"figures\"\n",
    "\n",
    "# NOAA COOPs\n",
    "const_data = project / \"constituent_data\"\n",
    "noaa_prediction_data = project / \"noaa_COOPs_prediction_data\"\n",
    "tidal_stations_fn = Path(\n",
    "    \"/mnt/e/MS_River_plume/ArcPro/MyProject/output data/tidal_constituents_stations.xlsx\"\n",
    ")\n",
    "\n",
    "tidal_stations_all = pd.read_excel(tidal_stations_fn, index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMmodel:\n",
    "    def __init__(self, case, case_name, study, model_output):\n",
    "        self.case = case\n",
    "        self.case_name = case_name\n",
    "        self.study = study\n",
    "        self.model_output = model_output\n",
    "        self.his_data = self.load_his(self.model_output / f\"{self.case}_0000_his.nc\")\n",
    "\n",
    "    def load_his(self, his_fn):\n",
    "        return (\n",
    "            xr.open_dataset(his_fn)\n",
    "            .swap_dims({\"stations\": \"station_name\"})\n",
    "            .drop_vars([\"station_id\"])\n",
    "        )\n",
    "\n",
    "    def create_comparison_data(self, stations):\n",
    "        wl_dataset = {}\n",
    "\n",
    "        for station in stations:\n",
    "            station_name = station.encode()\n",
    "            data = (\n",
    "                self.his_data[\"waterlevel\"]\n",
    "                .sel(station_name=station_name)\n",
    "                .to_dataframe()[\"waterlevel\"]\n",
    "            )\n",
    "            data.rename()\n",
    "            wl_dataset[station] = data\n",
    "\n",
    "        self.wl_dataset = wl_dataset\n",
    "        self.wl_curves = {\n",
    "            station: hv.Curve(wl, group=self.case, label=self.case)\n",
    "            for station, wl in wl_dataset.items()\n",
    "        }\n",
    "    \n",
    "    def demean_wl(self):\n",
    "        \n",
    "        self.demeaned_wl_dataset = {}\n",
    "        \n",
    "        for key, wl in self.wl_dataset.items():\n",
    "            mean_wl = wl.mean()\n",
    "            self.demeaned_wl_dataset[key] = wl - mean_wl\n",
    "        \n",
    "        self.demeaned_wl_curves = {\n",
    "            station: hv.Curve(wl, group=self.case, label=self.case)\n",
    "            for station, wl in self.demeaned_wl_dataset.items()\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up data\n",
    "# tidal stations to drop\n",
    "drop_stations = (\n",
    "    \"Pensacola\",\n",
    "    \"East Fowl River Bridge\",\n",
    "    \"Mobile State Docks\",\n",
    "    \"Chickasaw Creek\",\n",
    "    \"West Fowl River Bridge\",\n",
    "    \"Bayou La Batre Bridge\",\n",
    "    \"Grand Bay NERR, Mississippi Sound\",\n",
    "    \"Pascagoula NOAA Lab\",\n",
    "    \"Sabine Pass North\",\n",
    "    \"Texas Point, Sabine Pass\",\n",
    "    \"Weeks Bay, Mobile Bay\",\n",
    ")\n",
    "tidal_stations = tidal_stations_all[~tidal_stations_all.name.isin(drop_stations)]\n",
    "\n",
    "no_NAVD = [\n",
    "    \"Eugene_Island_North_of__Gulf_of_Mexico\",\n",
    "    \"I-10_Bonnet_Carre_Floodway\",\n",
    "    \"Port_Fourchon_Belle_Pass\",\n",
    "    \"Grand_Isle\",\n",
    "    \"Pilots_Station_East_S.W._Pass\",\n",
    "    \"Pilottown\",\n",
    "    \"Dog_River_Bridge\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOAA time series data\n",
    "begin_date = \"20180101\"\n",
    "end_date = \"20190101\"\n",
    "product = \"predictions\"\n",
    "interval = \"h\"\n",
    "datum = \"NAVD\"\n",
    "form = \"csv\"\n",
    "time_zone = \"gmt\"\n",
    "units = \"metric\"\n",
    "\n",
    "noaa_predicted_time_series = {}\n",
    "\n",
    "for _, (station_id, name) in tidal_stations[[\"id\", \"name\"]].iterrows():\n",
    "\n",
    "    # meta data\n",
    "    station_code = name.replace(\" \", \"_\").replace(\",\", \"\")\n",
    "    \n",
    "    if station_code in no_NAVD:\n",
    "        continue\n",
    "    \n",
    "    request = f\"https://tidesandcurrents.noaa.gov/api/datagetter?begin_date={begin_date}&end_date={end_date}&station={station_id}&product={product}&datum={datum}&units={units}&time_zone={time_zone}&application=ERDC&format={form}&interval={interval}\"\n",
    "    out_fn = noaa_prediction_data / f\"{station_code}_{product}_ts_{begin_date}-{end_date}_{datum}.csv\"\n",
    "\n",
    "    # conditionally download\n",
    "    if not out_fn.exists():\n",
    "        csv, http = urllib.request.urlretrieve(request, out_fn)\n",
    "        pass\n",
    "    else:\n",
    "        csv = out_fn\n",
    "        pass\n",
    "    \n",
    "    noaa_data = pd.read_csv(\n",
    "        csv,\n",
    "        index_col=[0],\n",
    "        parse_dates=True,\n",
    "        names=[\"time\", \"prediction\"],\n",
    "        header=0,\n",
    "        usecols=[0, 1]\n",
    "    )\n",
    "    noaa_predicted_time_series[station_code] = noaa_data.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOAA time series\n",
    "begin_date = \"20180101\"\n",
    "end_date = \"20190101\"\n",
    "product = \"predictions\"\n",
    "interval = \"h\"\n",
    "datum = \"MSL\"\n",
    "form = \"csv\"\n",
    "time_zone = \"gmt\"\n",
    "units = \"metric\"\n",
    "\n",
    "noaa_predicted_time_series_MSL = {}\n",
    "\n",
    "for _, (station_id, name) in tidal_stations[[\"id\", \"name\"]].iterrows():\n",
    "\n",
    "    # meta data\n",
    "    station_code = name.replace(\" \", \"_\").replace(\",\", \"\")\n",
    "    request = f\"https://tidesandcurrents.noaa.gov/api/datagetter?begin_date={begin_date}&end_date={end_date}&station={station_id}&product={product}&datum={datum}&units={units}&time_zone={time_zone}&application=ERDC&format={form}&interval={interval}\"\n",
    "    out_fn = noaa_prediction_data / f\"{station_code}_{product}_ts_{begin_date}-{end_date}_{datum}.csv\"\n",
    "\n",
    "    # conditionally download\n",
    "    if not out_fn.exists():\n",
    "        csv, http = urllib.request.urlretrieve(request, out_fn)\n",
    "        pass\n",
    "    else:\n",
    "        csv = out_fn\n",
    "        pass\n",
    "\n",
    "    noaa_data = pd.read_csv(\n",
    "        csv,\n",
    "        index_col=[0],\n",
    "        parse_dates=True,\n",
    "        names=[\"time\", \"prediction\"],\n",
    "        header=0,\n",
    "        usecols=[0, 1],\n",
    "    )\n",
    "    noaa_predicted_time_series_MSL[station_code] = noaa_data.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOAA observed time series data\n",
    "begin_date = \"20180101\"\n",
    "end_date = \"20190101\"\n",
    "product = \"hourly_height\"\n",
    "interval = \"h\"\n",
    "datum = \"NAVD\"\n",
    "form = \"csv\"\n",
    "time_zone = \"gmt\"\n",
    "units = \"metric\"\n",
    "\n",
    "noaa_measured_time_series = {}\n",
    "\n",
    "for _, (station_id, name) in tidal_stations[[\"id\", \"name\"]].iterrows():\n",
    "\n",
    "    # meta data\n",
    "    station_code = name.replace(\" \", \"_\").replace(\",\", \"\")\n",
    "    \n",
    "    if station_code in no_NAVD:\n",
    "        continue\n",
    "    \n",
    "    request = f\"https://tidesandcurrents.noaa.gov/api/datagetter?begin_date={begin_date}&end_date={end_date}&station={station_id}&product={product}&datum={datum}&units={units}&time_zone={time_zone}&application=ERDC&format={form}\"\n",
    "    out_fn = noaa_prediction_data / f\"{station_code}_{product}_ts_{begin_date}-{end_date}_{datum}.csv\"\n",
    "\n",
    "    # conditionally download\n",
    "    if not out_fn.exists():\n",
    "        csv, http = urllib.request.urlretrieve(request, out_fn)\n",
    "        pass\n",
    "    else:\n",
    "        csv = out_fn\n",
    "        pass\n",
    "\n",
    "    noaa_data = pd.read_csv(\n",
    "        csv,\n",
    "        index_col=[0],\n",
    "        parse_dates=True,\n",
    "        names=[\"time\", \"waterlevel\"],\n",
    "        header=0,\n",
    "        usecols=[0, 1],\n",
    "    )\n",
    "    noaa_measured_time_series[station_code] = noaa_data.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOAA observed time series data\n",
    "begin_date = \"20180101\"\n",
    "end_date = \"20190101\"\n",
    "product = \"hourly_height\"\n",
    "interval = \"h\"\n",
    "datum = \"MSL\"\n",
    "form = \"csv\"\n",
    "time_zone = \"gmt\"\n",
    "units = \"metric\"\n",
    "\n",
    "noaa_measured_time_series_MSL = {}\n",
    "\n",
    "for _, (station_id, name) in tidal_stations[[\"id\", \"name\"]].iterrows():\n",
    "\n",
    "    # meta data\n",
    "    station_code = name.replace(\" \", \"_\").replace(\",\", \"\")\n",
    "    request = f\"https://tidesandcurrents.noaa.gov/api/datagetter?begin_date={begin_date}&end_date={end_date}&station={station_id}&product={product}&datum={datum}&units={units}&time_zone={time_zone}&application=ERDC&format={form}\"\n",
    "    out_fn = noaa_prediction_data / f\"{station_code}_{product}_ts_{datum}.csv\"\n",
    "\n",
    "    # conditionally download\n",
    "    if not out_fn.exists():\n",
    "        csv, http = urllib.request.urlretrieve(request, out_fn)\n",
    "        pass\n",
    "    else:\n",
    "        csv = out_fn\n",
    "        pass\n",
    "\n",
    "    noaa_data = pd.read_csv(\n",
    "        csv,\n",
    "        index_col=[0],\n",
    "        parse_dates=True,\n",
    "        names=[\"time\", \"waterlevel\"],\n",
    "        header=0,\n",
    "        usecols=[0, 1],\n",
    "    )\n",
    "    \n",
    "    noaa_measured_time_series_MSL[station_code] = noaa_data.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observation stations\n",
    "stations = list(noaa_measured_time_series_MSL.keys())\n",
    "\n",
    "# combine\n",
    "reference_values = {\n",
    "    \"predicted\": noaa_predicted_time_series,\n",
    "    \"predicted_MSL\": noaa_predicted_time_series_MSL,\n",
    "    \"verified\": noaa_measured_time_series,\n",
    "    \"verified_MSL\": noaa_measured_time_series_MSL,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model results\n",
    "model_ref = pd.to_datetime('2018-01-01 00:00:00')\n",
    "study = \"roughness_calibration\"\n",
    "\n",
    "case = \"r01\"\n",
    "case_name = f\"{case}_10sig_adcirc11\"\n",
    "model_output = data / f\"Delft3d/models/{study}/{case_name}/output\"\n",
    "\n",
    "r01 = FMmodel(case, case_name, study, model_output)\n",
    "r01.create_comparison_data(stations)\n",
    "r01.demean_wl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model results\n",
    "model_ref = pd.to_datetime('2018-01-01 00:00:00')\n",
    "study = \"roughness_calibration\"\n",
    "\n",
    "case = \"r02\"\n",
    "case_name = f\"{case}_10sig_default_0023\"\n",
    "model_output = data / f\"Delft3d/models/{study}/{case_name}/output\"\n",
    "\n",
    "r02 = FMmodel(case, case_name, study, model_output)\n",
    "r02.create_comparison_data(stations)\n",
    "r02.demean_wl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model results\n",
    "model_ref = pd.to_datetime('2018-01-01 00:00:00')\n",
    "study = \"tidal_calibration\"\n",
    "\n",
    "case = \"td_01\"\n",
    "case_name = f\"{case}_1sig_base\"\n",
    "model_output = data / f\"Delft3d/models/{study}/{case_name}/output\"\n",
    "\n",
    "td_01 = FMmodel(case, case_name, study, model_output)\n",
    "td_01.create_comparison_data(stations)\n",
    "td_01.demean_wl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model results\n",
    "model_ref = pd.to_datetime('2038-03-03 00:00:00')\n",
    "study = \"tidal_calibration\"\n",
    "\n",
    "case = \"td03\"\n",
    "case_name = f\"{case}_1sig_rough\"\n",
    "model_output = data / f\"Delft3d/models/{study}/{case_name}/output\"\n",
    "\n",
    "td03 = FMmodel(case, case_name, study, model_output)\n",
    "td03.create_comparison_data(stations)\n",
    "td03.demean_wl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model results\n",
    "model_ref = pd.to_datetime('2018-01-01 00:00:00')\n",
    "study = \"tidal_calibration\"\n",
    "\n",
    "case = \"t11\"\n",
    "case_name = f\"{case}_solar_corr\"\n",
    "model_output = data / f\"Delft3d/models/{study}/{case_name}/output\"\n",
    "\n",
    "t11 = FMmodel(case, case_name, study, model_output)\n",
    "t11.create_comparison_data(stations)\n",
    "t11.demean_wl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model results\n",
    "model_ref = pd.to_datetime('2018-01-01 00:00:00')\n",
    "study = \"three_dimensional\"\n",
    "\n",
    "case = \"f07\"\n",
    "case_name = f\"{case}_10sig_davg_sal_rst\"\n",
    "model_output = data / f\"Delft3d/models/{study}/{case_name}/output\"\n",
    "\n",
    "f07 = FMmodel(case, case_name, study, model_output)\n",
    "f07.create_comparison_data(stations)\n",
    "f07.demean_wl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = \"meteo_testing\"\n",
    "\n",
    "case = \"m01\"\n",
    "case_name = f\"{case}_10sig_default\"\n",
    "model_output = data / f\"Delft3d/models/{study}/{case_name}/output\"\n",
    "\n",
    "m01 = FMmodel(case, case_name, study, model_output)\n",
    "m01.create_comparison_data(stations)\n",
    "m01.demean_wl()\n",
    "\n",
    "case = \"m02\"\n",
    "case_name = f\"{case}_10sig_cfsv2\"\n",
    "model_output = data / f\"Delft3d/models/{study}/{case_name}/output\"\n",
    "\n",
    "m02 = FMmodel(case, case_name, study, model_output)\n",
    "m02.create_comparison_data(stations)\n",
    "m02.demean_wl()\n",
    "\n",
    "case = \"m03\"\n",
    "case_name = f\"{case}_10sig_ncar_rean2\"\n",
    "model_output = data / f\"Delft3d/models/{study}/{case_name}/output\"\n",
    "\n",
    "m03 = FMmodel(case, case_name, study, model_output)\n",
    "m03.create_comparison_data(stations)\n",
    "m03.demean_wl()\n",
    "\n",
    "case = \"m04\"\n",
    "case_name = f\"{case}_10sig_era5\"\n",
    "model_output = data / f\"Delft3d/models/{study}/{case_name}/output\"\n",
    "\n",
    "m04 = FMmodel(case, case_name, study, model_output)\n",
    "m04.create_comparison_data(stations)\n",
    "m04.demean_wl()\n",
    "\n",
    "case = \"m05\"\n",
    "case_name = f\"{case}_10sig_era5_elias\"\n",
    "model_output = data / f\"Delft3d/models/{study}/{case_name}/output\"\n",
    "\n",
    "m05 = FMmodel(case, case_name, study, model_output)\n",
    "m05.create_comparison_data(stations)\n",
    "m05.demean_wl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdims = hv.Dimension(\"station\", default=\"Dauphin_Island\")\n",
    "\n",
    "holomap_obs = hv.HoloMap(\n",
    "    {\n",
    "        station: hv.Curve(wl, group=\"obs\", label=\"obs\")\n",
    "        for station, wl in reference_values[\"verified_MSL\"].items()\n",
    "    },\n",
    "    kdims=kdims,\n",
    "    label=\"obs\",\n",
    ")\n",
    "\n",
    "holomap_pred = hv.HoloMap(\n",
    "    {\n",
    "        station: hv.Curve(wl, group=\"pred\", label=\"pred.\")\n",
    "        for station, wl in reference_values[\"predicted_MSL\"].items()\n",
    "    },\n",
    "    kdims=kdims,\n",
    "    label=\"pred.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holomap4 = hv.HoloMap(td_01.demeaned_wl_curves, kdims=kdims)\n",
    "holomap5 = hv.HoloMap(t11.demeaned_wl_curves, kdims=kdims)\n",
    "holomap6 = hv.HoloMap(td03.demeaned_wl_curves, kdims=kdims)\n",
    "overlay = holomap4 * holomap6 * holomap_pred\n",
    "overlay.opts(\n",
    "    opts.Curve(width=1400, height=900),\n",
    "    opts.Curve(\"pred\", color=\"blue\"),\n",
    "    opts.Curve(\"td_01\", color=\"black\"),\n",
    "    opts.Curve(\"t11\", color=\"red\"),\n",
    "    opts.Curve(\"td03\", color=\"green\")\n",
    ").opts(\n",
    "    show_grid=True,\n",
    "    xlim=(pd.to_datetime(\"2018-01-15\"), pd.to_datetime(\"2018-02-15\")),\n",
    "    ylim=(-1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holomap1 = hv.HoloMap(m04.demeaned_wl_curves, kdims=kdims)\n",
    "holomap2 = hv.HoloMap(m05.demeaned_wl_curves, kdims=kdims)\n",
    "holomap3 = hv.HoloMap(f07.demeaned_wl_curves, kdims=kdims)\n",
    "\n",
    "overlay = holomap1 * holomap2 * holomap_obs\n",
    "overlay.opts(\n",
    "    opts.Curve(width=1400, height=900),\n",
    "    opts.Curve(\"m04\", color=\"red\"),\n",
    "    opts.Curve(\"m05\", color=\"black\"),\n",
    "    opts.Curve(\"obs\", color=\"blue\", line_dash=\"solid\"),\n",
    ").opts(\n",
    "    show_grid=True,\n",
    "    xlim=(pd.to_datetime(\"2018-01-15\"), pd.to_datetime(\"2018-02-15\")),\n",
    "    ylim=(-1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holomap_r01 = hv.HoloMap(r01.demeaned_wl_curves, kdims=kdims)\n",
    "holomap_r02 = hv.HoloMap(r02.demeaned_wl_curves, kdims=kdims)\n",
    "\n",
    "overlay = holomap_r01 * holomap_r02 * holomap_obs\n",
    "overlay.opts(\n",
    "    opts.Curve(width=1400, height=900),\n",
    "    opts.Curve(\"r02\", color=\"red\"),\n",
    "    opts.Curve(\"r01\", color=\"black\"),\n",
    "    opts.Curve(\"obs\", color=\"blue\", line_dash=\"solid\"),\n",
    ").opts(\n",
    "    show_grid=True,\n",
    "    xlim=(pd.to_datetime(\"2018-01-15\"), pd.to_datetime(\"2018-02-15\")),\n",
    "    ylim=(-1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holomap_m01 = hv.HoloMap(m01.demeaned_wl_curves, kdims=kdims)\n",
    "holomap_m02 = hv.HoloMap(m02.demeaned_wl_curves, kdims=kdims)\n",
    "holomap_m03 = hv.HoloMap(m03.demeaned_wl_curves, kdims=kdims)\n",
    "holomap_m04 = hv.HoloMap(m04.demeaned_wl_curves, kdims=kdims)\n",
    "holomap_m05 = hv.HoloMap(m05.demeaned_wl_curves, kdims=kdims)\n",
    "\n",
    "overlay = holomap_m01 * holomap_m02 * holomap_m03 * holomap_m04 * holomap_m05 * holomap_obs\n",
    "overlay.opts(\n",
    "    opts.Curve(width=1400, height=900),\n",
    "    opts.Curve(\"m02\", color=\"red\"),\n",
    "    opts.Curve(\"m01\", color=\"black\"),\n",
    "    opts.Curve(\"m03\", color=\"green\"),\n",
    "    opts.Curve(\"m04\", color=\"yellow\"),\n",
    "    opts.Curve(\"m05\", color=\"purple\"),\n",
    "    opts.Curve(\"obs\", color=\"blue\", line_dash=\"solid\"),\n",
    ").opts(\n",
    "    show_grid=True,\n",
    "    xlim=(pd.to_datetime(\"2018-01-15\"), pd.to_datetime(\"2018-02-15\")),\n",
    "    ylim=(-1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
