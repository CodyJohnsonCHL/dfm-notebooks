{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import cartopy.crs as ccrs\n",
    "import seaborn as sns\n",
    "from VVUQ  import metrics\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting function\n",
    "def one2one(obs, mod, quantity_str=\"water level [m, NAVD88]\", lims=None, ax=None):\n",
    "    std = obs.std()\n",
    "    std_shift = np.sin(np.pi / 4) * std\n",
    "    \n",
    "    if lims == None:\n",
    "        lims = [np.min([obs.min(), mod.min()]), np.max([obs.max(), mod.max()])]\n",
    "\n",
    "    lower_bound_x = [lims[0] + std_shift, lims[1]]\n",
    "    lower_bound_y = [lims[0], lims[1] - std_shift]\n",
    "    upper_bound_x = [lims[0], lims[1] - std_shift]\n",
    "    upper_bound_y = [lims[0] + std_shift, lims[1]]\n",
    "\n",
    "    fill_between_x = lims\n",
    "    fill_between_y1 = [lims[0] - std_shift, lims[1] - std_shift]\n",
    "    fill_between_y2 = [lims[0] + std_shift, lims[1] + std_shift]\n",
    "\n",
    "    if ax == None:\n",
    "        fig, ax = plt.subplots(figsize=(5, 5))\n",
    "        ax.scatter(obs, mod, 15)\n",
    "        ax.plot(lims, lims, color=\"k\", linestyle=\"--\")\n",
    "\n",
    "        ax.plot(lower_bound_x, lower_bound_y, color=\"k\", lw=0.75)\n",
    "        ax.plot(upper_bound_x, upper_bound_y, color=\"k\", lw=0.75)\n",
    "        ax.fill_between(\n",
    "            fill_between_x, fill_between_y1, fill_between_y2, alpha=0.2, color=\"gray\"\n",
    "        )\n",
    "        ax.set_xlim(lims)\n",
    "        ax.set_ylim(lims)\n",
    "        ax.set_xlabel(f\"observed {quantity_str}\")\n",
    "        ax.set_ylabel(f\"modeled {quantity_str}\")\n",
    "\n",
    "        return fig, ax\n",
    "    else:\n",
    "        ax.scatter(obs, mod, 15)\n",
    "        ax.plot(lims, lims, color=\"k\", linestyle=\"--\")\n",
    "\n",
    "        ax.plot(lower_bound_x, lower_bound_y, color=\"k\", lw=0.75)\n",
    "        ax.plot(upper_bound_x, upper_bound_y, color=\"k\", lw=0.75)\n",
    "        ax.fill_between(\n",
    "            fill_between_x, fill_between_y1, fill_between_y2, alpha=0.2, color=\"gray\"\n",
    "        )\n",
    "        ax.set_xlim(lims)\n",
    "        ax.set_ylim(lims)\n",
    "        ax.set_xlabel(f\"observed {quantity_str}\")\n",
    "        ax.set_ylabel(f\"modeled {quantity_str}\")\n",
    "        return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project files\n",
    "#d3d = Path(\"C:\\\\Users\\\\rdchlclj\\\\Projects\\\\MR_D3D_model\\\\Delft3D\")\n",
    "d3d = Path(\"/mnt/c/Users/rdchlclj/Projects/MR_D3D_model/Delft3D\")\n",
    "# data = Path('H:\\\\MR_Plume_D3D_data')\n",
    "#data = Path(\"D:\\\\MS_River_plume\")\n",
    "data = Path(\"/mnt/d/MS_River_plume\")\n",
    "data = Path(\"/mnt/e/MS_River_plume\")\n",
    "project = d3d / \"tidal_constituent_boundary_conditions\"\n",
    "output = project / \"output\"\n",
    "figures = project / \"figures\"\n",
    "\n",
    "# NOAA COOPs\n",
    "const_data = project / \"constituent_data\"\n",
    "noaa_prediction_data = project / \"noaa_COOPs_prediction_data\"\n",
    "tidal_stations_fn = Path(\n",
    "    \"/mnt/e/MS_River_plume/ArcPro/MyProject/output data/tidal_constituents_stations.xlsx\"\n",
    ")\n",
    "#tidal_stations_fn = Path(\n",
    "#    \"E:\\\\ArcPro\\\\MyProject\\\\output data\\\\tidal_constituents_stations.xlsx\"\n",
    "#)\n",
    "tidal_stations_all = pd.read_excel(tidal_stations_fn, index_col=[0])\n",
    "\n",
    "# msl to navd88\n",
    "datum_conversion_fn = output / \"tidal_stations_msl_to_navd88_vdatum.txt\"\n",
    "datum_conversion = pd.read_csv(datum_conversion_fn, na_values=[-999999], index_col=[0])\n",
    "\n",
    "# model boundary condition constituents\n",
    "FES_comps = pd.read_csv(\n",
    "    \"example_FES2014_comps.txt\",\n",
    "    sep=\"\\s+\",\n",
    "    names=[\"name\", \"amp\", \"phase\"],\n",
    "    index_col=[0],\n",
    ")\n",
    "\n",
    "# model data\n",
    "case = \"m05\"\n",
    "case_name = f\"{case}_10sig_era5_elias\"\n",
    "study = \"meteo_testing\"\n",
    "model_output = data / f\"Delft3d/models/{study}/{case_name}/output\"\n",
    "#his_fn = output / f\"{case_name}_combined_his.nc\"\n",
    "his_fn = model_output / f\"{case}_0000_his.nc\"\n",
    "his_data = (\n",
    "    xr.open_dataset(his_fn)\n",
    "    .swap_dims({\"stations\": \"station_name\"})\n",
    "    .drop_vars([\"station_id\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate non-NOAA tide station output\n",
    "all_stations = his_data.coords[\"station_name\"].values\n",
    "NOAA_stations = [\"4\" not in str(t) for t in all_stations]  # NDBC station codes\n",
    "NOAA_stations = all_stations[NOAA_stations]\n",
    "noaa_his_data = his_data.sel(station_name=NOAA_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up data\n",
    "# tidal stations to drop\n",
    "drop_stations = (\n",
    "    'Pensacola',\n",
    "    'East Fowl River Bridge',\n",
    "    'Mobile State Docks',\n",
    "    'Chickasaw Creek',\n",
    "    'West Fowl River Bridge',\n",
    "    'Bayou La Batre Bridge',\n",
    "    'Grand Bay NERR, Mississippi Sound',\n",
    "    'Pascagoula NOAA Lab',\n",
    "    'Sabine Pass North',\n",
    "    'Texas Point, Sabine Pass'\n",
    ")\n",
    "tidal_stations = tidal_stations_all[~tidal_stations_all.name.isin(drop_stations)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# download datums and constants from NOAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_amp_phase(harcon):\n",
    "    const = harcon['HarmonicConstituents']\n",
    "    names = []\n",
    "    amps = []\n",
    "    phases_GMT = []\n",
    "    speeds = []\n",
    "    for component in const:\n",
    "        names.append(component['name'])\n",
    "        amps.append(component['amplitude'])\n",
    "        phases_GMT.append(component['phase_GMT'])\n",
    "        speeds.append(component['speed'])\n",
    "        pass\n",
    "    return names, amps, phases_GMT, speeds\n",
    "\n",
    "def get_datums(datums):\n",
    "    \"\"\"interate over NOAA datum list and compute shifts\"\"\"\n",
    "    for datum in datums:\n",
    "        if datum['name'] == 'STND':\n",
    "            STND = datum['value']\n",
    "            pass\n",
    "        elif datum['name'] == 'MTL':\n",
    "            MTL = datum['value']\n",
    "            pass\n",
    "        elif datum['name'] == 'MSL':\n",
    "            MSL = datum['value']\n",
    "            pass\n",
    "        elif datum['name'] == 'NAVD88':\n",
    "            NAVD88 = datum['value']\n",
    "            pass\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        NAVD88\n",
    "        pass\n",
    "    except:\n",
    "        NAVD88 = np.nan\n",
    "    \n",
    "    return STND, MTL, MSL, NAVD88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get datums\n",
    "station_ids = []\n",
    "station_names = []\n",
    "station_codes = []\n",
    "STND = []\n",
    "MTL = []\n",
    "MSL = []\n",
    "NAVD88 = []\n",
    "datums = []\n",
    "\n",
    "for _, (station_id, name) in tidal_stations[['id', 'name']].iterrows():\n",
    "    \n",
    "    # meta data\n",
    "    station_code = name.replace(' ', '_').replace(',', '')\n",
    "    station_name = name.replace(' ', '_') + '_datums.json'\n",
    "    station_ids.append(station_id)\n",
    "    resource = 'datums'\n",
    "    request = f'http://tidesandcurrents.noaa.gov/mdapi/v1.0/webapi/stations/{station_id}/{resource}.json?units=metric'\n",
    "    station_codes.append(station_code)\n",
    "    station_names.append(station_name.strip('.json'))\n",
    "    out_fn = noaa_prediction_data / f'{station_name}'\n",
    "    \n",
    "    # conditionally download\n",
    "    if not out_fn.exists():\n",
    "        txt, http = urllib.request.urlretrieve(request, out_fn)\n",
    "        pass\n",
    "    else:\n",
    "        txt = out_fn\n",
    "        pass\n",
    "    \n",
    "    # parse json\n",
    "    with open(txt, 'r') as f:\n",
    "        response = json.load(f)\n",
    "        pass\n",
    "    \n",
    "    datums  = get_datums(response['datums'])\n",
    "    \n",
    "    STND.append(datums[0])\n",
    "    MTL.append(datums[1])\n",
    "    MSL.append(datums[2])\n",
    "    NAVD88.append(datums[3])\n",
    "\n",
    "# create DataFrames\n",
    "datums = pd.DataFrame({'station_id': station_ids, 'MTL': MTL, 'MSL': MSL, 'NAVD88': NAVD88}, index=station_codes)\n",
    "datums['MSL2NAVD88'] = datums['MSL'] - datums['NAVD88']\n",
    "datums['MTL_NAVD88'] = datums['MTL'] - datums['NAVD88']\n",
    "compare_datum_conv = datums.join(datum_conversion, on='station_id', rsuffix='_vdatum').drop(['latitude', 'longitude'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "amplitudes = []\n",
    "phase_angles = []\n",
    "speeds = []\n",
    "station_ids = []\n",
    "station_names = []\n",
    "station_codes = []\n",
    "\n",
    "for _, (station_id, name) in tidal_stations[['id', 'name']].iterrows():\n",
    "    \n",
    "    # meta data\n",
    "    station_code = name.replace(' ', '_').replace(',', '')\n",
    "    station_name = name.replace(' ', '_') + '.json'\n",
    "    station_ids.append(station_id)\n",
    "    resource = 'harcon'\n",
    "    request = f'https://tidesandcurrents.noaa.gov/mdapi/v1.0/webapi/stations/{station_id}/{resource}.json?units=metric'\n",
    "    station_codes.append(station_code)\n",
    "    station_names.append(station_name.strip('.json'))\n",
    "    out_fn = const_data / f'{station_name}'\n",
    "    \n",
    "    # conditionally download\n",
    "    if not out_fn.exists():\n",
    "        txt, http = urllib.request.urlretrieve(request, out_fn)\n",
    "        pass\n",
    "    else:\n",
    "        txt = out_fn\n",
    "        pass\n",
    "    \n",
    "    # parse json\n",
    "    with open(txt, 'r') as f:\n",
    "        harcon = json.load(f)\n",
    "        names, amps, phases, speed = get_amp_phase(harcon)\n",
    "        tmp_ser = pd.Series(amps, index=names)\n",
    "        amplitudes.append(tmp_ser)\n",
    "        tmp_ser2 = pd.Series(phases, index=names)\n",
    "        phase_angles.append(tmp_ser2)\n",
    "        tmp_ser3 = pd.Series(speed, index=names)\n",
    "        speeds.append(tmp_ser3)\n",
    "        pass\n",
    "\n",
    "# create DataFrames\n",
    "amplitudes = pd.DataFrame(amplitudes, columns=names, index=station_codes)\n",
    "phase_angles = pd.DataFrame(phase_angles, columns=names, index=station_codes)\n",
    "speeds = pd.DataFrame(speeds, columns=names, index=station_codes)\n",
    "station_lookup = pd.Series(station_ids, index=station_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_stations = [station.strip('\"') for station in nc_res.station_list(his_data)]\n",
    "model_ref = pd.to_datetime('2018-01-01 00:00:00')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_analysis_model(waterlevel, consts):\n",
    "    time = waterlevel[\"time\"].values.astype(\"datetime64[s]\")\n",
    "\n",
    "    wt = pytide.WaveTable(consts)\n",
    "    h = waterlevel.values\n",
    "    f, vu = wt.compute_nodal_modulations(time)\n",
    "    w = wt.harmonic_analysis(h, f, vu)\n",
    "    hp = wt.tide_from_tide_series(time, w)\n",
    "    return w, (h, hp, time)\n",
    "\n",
    "\n",
    "def get_modulus_angle(w):\n",
    "    modulus = np.abs(w)\n",
    "    angle = np.angle(w, deg=True)\n",
    "    return modulus, angle\n",
    "\n",
    "\n",
    "def get_results(w, amplitude, phase_angle):\n",
    "\n",
    "    cols = [\n",
    "        \"model_amp\",\n",
    "        \"noaa_amp\",\n",
    "        \"amp_error\",\n",
    "        \"model_phase\",\n",
    "        \"noaa_phase\",\n",
    "        \"phase_error\",\n",
    "    ]\n",
    "    modulus, angle = get_modulus_angle(w)\n",
    "    angle[angle < 0] = angle[angle < 0] + 360\n",
    "\n",
    "    results = pd.DataFrame(\n",
    "        np.stack([modulus, angle], axis=1),\n",
    "        index=amplitude.index,\n",
    "        columns=[\"model_amp\", \"model_phase\"],\n",
    "    )\n",
    "    results[\"amp_error\"] = results[\"model_amp\"] - amplitude\n",
    "    results[\"phase_error\"] = results[\"model_phase\"] - phase_angle\n",
    "    results[\"noaa_amp\"] = amplitude\n",
    "    results[\"noaa_phase\"] = phase_angle\n",
    "\n",
    "    return results[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 10 consts in BCs\n",
    "additional_consts = [\"SA\", \"SSA\"]\n",
    "top = 13\n",
    "important_consts = (\n",
    "    FES_comps.sort_values([\"amp\"], ascending=False)\n",
    "    .iloc[:top]\n",
    "    .append(FES_comps.loc[additional_consts])\n",
    ")\n",
    "important_consts_order = important_consts.index.values\n",
    "important_consts_caps = important_consts.index.str.capitalize().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOAA time series data\n",
    "begin_date = \"20180101\"\n",
    "end_date = \"20190101\"\n",
    "product = \"predictions\"\n",
    "interval = \"h\"\n",
    "datum = \"NAVD\"\n",
    "form = \"csv\"\n",
    "time_zone = \"gmt\"\n",
    "units = \"metric\"\n",
    "\n",
    "noaa_predicted_time_series = {}\n",
    "\n",
    "for _, (station_id, name) in tidal_stations[[\"id\", \"name\"]].iterrows():\n",
    "\n",
    "    # meta data\n",
    "    station_code = name.replace(\" \", \"_\").replace(\",\", \"\")\n",
    "    request = f\"https://tidesandcurrents.noaa.gov/api/datagetter?begin_date={begin_date}&end_date={end_date}&station={station_id}&product={product}&datum={datum}&units={units}&time_zone={time_zone}&application=ERDC&format={form}&interval={interval}\"\n",
    "    out_fn = noaa_prediction_data / f\"{station_code}_{product}_ts_{datum}.csv\"\n",
    "\n",
    "    # conditionally download\n",
    "    if not out_fn.exists():\n",
    "        csv, http = urllib.request.urlretrieve(request, out_fn)\n",
    "        pass\n",
    "    else:\n",
    "        csv = out_fn\n",
    "        pass\n",
    "\n",
    "    noaa_data = pd.read_csv(\n",
    "        csv, index_col=[0], parse_dates=True, names=[\"time\", \"prediction\"], header=0\n",
    "    )\n",
    "    noaa_predicted_time_series[station_code] = noaa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOAA time series\n",
    "begin_date = \"20180101\"\n",
    "end_date = \"20190101\"\n",
    "product = \"predictions\"\n",
    "interval = \"h\"\n",
    "datum = \"MSL\"\n",
    "form = \"csv\"\n",
    "time_zone = \"gmt\"\n",
    "units = \"metric\"\n",
    "\n",
    "noaa_predicted_time_series_MSL = {}\n",
    "\n",
    "for _, (station_id, name) in tidal_stations[[\"id\", \"name\"]].iterrows():\n",
    "\n",
    "    # meta data\n",
    "    station_code = name.replace(\" \", \"_\").replace(\",\", \"\")\n",
    "    request = f\"https://tidesandcurrents.noaa.gov/api/datagetter?begin_date={begin_date}&end_date={end_date}&station={station_id}&product={product}&datum={datum}&units={units}&time_zone={time_zone}&application=ERDC&format={form}&interval={interval}\"\n",
    "    out_fn = noaa_prediction_data / f\"{station_code}_{product}_ts_{datum}.csv\"\n",
    "\n",
    "    # conditionally download\n",
    "    if not out_fn.exists():\n",
    "        csv, http = urllib.request.urlretrieve(request, out_fn)\n",
    "        pass\n",
    "    else:\n",
    "        csv = out_fn\n",
    "        pass\n",
    "\n",
    "    noaa_data = pd.read_csv(\n",
    "        csv, index_col=[0], parse_dates=True, names=[\"time\", \"prediction\"], header=0\n",
    "    )\n",
    "    noaa_predicted_time_series_MSL[station_code] = noaa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOAA observed time series data\n",
    "begin_date = \"20180101\"\n",
    "end_date = \"20190101\"\n",
    "product = \"hourly_height\"\n",
    "interval = \"h\"\n",
    "datum = \"NAVD\"\n",
    "form = \"csv\"\n",
    "time_zone = \"gmt\"\n",
    "units = \"metric\"\n",
    "\n",
    "noaa_measured_time_series = {}\n",
    "\n",
    "for _, (station_id, name) in tidal_stations[[\"id\", \"name\"]].iterrows():\n",
    "\n",
    "    # meta data\n",
    "    station_code = name.replace(\" \", \"_\").replace(\",\", \"\")\n",
    "    request = f\"https://tidesandcurrents.noaa.gov/api/datagetter?begin_date={begin_date}&end_date={end_date}&station={station_id}&product={product}&datum={datum}&units={units}&time_zone={time_zone}&application=ERDC&format={form}\"\n",
    "    out_fn = noaa_prediction_data / f\"{station_code}_{product}_ts_{datum}.csv\"\n",
    "\n",
    "    # conditionally download\n",
    "    if not out_fn.exists():\n",
    "        csv, http = urllib.request.urlretrieve(request, out_fn)\n",
    "        pass\n",
    "    else:\n",
    "        csv = out_fn\n",
    "        pass\n",
    "\n",
    "    noaa_data = pd.read_csv(\n",
    "        csv,\n",
    "        index_col=[0],\n",
    "        parse_dates=True,\n",
    "        names=[\"time\", \"water_level\"],\n",
    "        header=0,\n",
    "        usecols=[0, 1],\n",
    "    )\n",
    "    noaa_measured_time_series[station_code] = noaa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOAA observed time series data\n",
    "begin_date = \"20180101\"\n",
    "end_date = \"20190101\"\n",
    "product = \"hourly_height\"\n",
    "interval = \"h\"\n",
    "datum = \"MSL\"\n",
    "form = \"csv\"\n",
    "time_zone = \"gmt\"\n",
    "units = \"metric\"\n",
    "\n",
    "noaa_measured_time_series_MSL = {}\n",
    "\n",
    "for _, (station_id, name) in tidal_stations[[\"id\", \"name\"]].iterrows():\n",
    "\n",
    "    # meta data\n",
    "    station_code = name.replace(\" \", \"_\").replace(\",\", \"\")\n",
    "    request = f\"https://tidesandcurrents.noaa.gov/api/datagetter?begin_date={begin_date}&end_date={end_date}&station={station_id}&product={product}&datum={datum}&units={units}&time_zone={time_zone}&application=ERDC&format={form}\"\n",
    "    out_fn = noaa_prediction_data / f\"{station_code}_{product}_ts_{datum}.csv\"\n",
    "\n",
    "    # conditionally download\n",
    "    if not out_fn.exists():\n",
    "        csv, http = urllib.request.urlretrieve(request, out_fn)\n",
    "        pass\n",
    "    else:\n",
    "        csv = out_fn\n",
    "        pass\n",
    "\n",
    "    noaa_data = pd.read_csv(\n",
    "        csv,\n",
    "        index_col=[0],\n",
    "        parse_dates=True,\n",
    "        names=[\"time\", \"water_level\"],\n",
    "        header=0,\n",
    "        usecols=[0, 1],\n",
    "    )\n",
    "    noaa_measured_time_series_MSL[station_code] = noaa_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = {\"font.size\": 16}\n",
    "nrmse_col = []\n",
    "rmse_col = []\n",
    "error_col = []\n",
    "r2_col = []\n",
    "xs = []\n",
    "ys = []\n",
    "good_stations = []\n",
    "datum = \"NAVD88\"\n",
    "norm = \"tide\"\n",
    "aligned_data = {}\n",
    "stop_wl = -5\n",
    "\n",
    "# t0 = pd.to_datetime(begin_date)\n",
    "# tf = pd.to_datetime(end_date)\n",
    "# tf = pd.to_datetime('2018-06-25 9:00')\n",
    "\n",
    "# drop restart data\n",
    "# t1 = pd.to_datetime('2018-04-01')\n",
    "# t2 = pd.to_datetime('2018-05-01')\n",
    "# drop_times = pd.date_range(t1, t2, freq='H')\n",
    "\n",
    "t0 = noaa_his_data.time[0].values\n",
    "#t0 = pd.to_datetime(\"2018-01-15\")\n",
    "tf = noaa_his_data.time[-1].values\n",
    "\n",
    "with plt.rc_context(rc=rc):\n",
    "    for station in noaa_his_data.coords[\"station_name\"].values[:stop_wl]:\n",
    "        waterlevel = noaa_his_data[\"waterlevel\"].loc[t0:tf, station]\n",
    "        station = station.decode(\"ascii\")\n",
    "\n",
    "        # quick fix for error in station name\n",
    "        if station == \"ilots_Station_East_S.W._Pass\":\n",
    "            station = \"Pilots_Station_East_S.W._Pass\"\n",
    "\n",
    "        # exclude observation points outside domain\n",
    "        if np.isnan(waterlevel).all():\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # excludes NOAA which didn't have datum\n",
    "        noaa_data = noaa_measured_time_series[station].loc[t0:tf]\n",
    "        if not noaa_data[\"water_level\"].any():\n",
    "            continue\n",
    "\n",
    "        predicted_noaa_data = noaa_predicted_time_series_MSL[station]\n",
    "        predicted_noaa_data = noaa_predicted_time_series_MSL[station].loc[t0:tf]\n",
    "\n",
    "        # D3D results\n",
    "        xs.append(waterlevel[\"station_x_coordinate\"])\n",
    "        ys.append(waterlevel[\"station_y_coordinate\"])\n",
    "        good_stations.append(station)\n",
    "        \n",
    "        # align\n",
    "        df = pd.DataFrame(columns=[\"modeled\", \"observed\"], index=noaa_data.index)\n",
    "        df[\"modeled\"] = waterlevel.loc[noaa_data.index]\n",
    "        df[\"observed\"] = noaa_data[\"water_level\"]\n",
    "        aligned_data[station] = df\n",
    "\n",
    "        # stats\n",
    "        rmse = np.sqrt(\n",
    "            np.mean((waterlevel.to_series() - noaa_data[\"water_level\"]) ** 2)\n",
    "        )\n",
    "        \n",
    "        if norm == \"tide\":\n",
    "            nrmse = rmse / (\n",
    "                predicted_noaa_data[\"prediction\"].max() - predicted_noaa_data[\"prediction\"].min()\n",
    "            )\n",
    "        elif norm == \"water_level\":\n",
    "            nrmse = rmse / (noaa_data[\"water_level\"].max() - noaa_data[\"water_level\"].min())\n",
    "            \n",
    "        error = np.mean(waterlevel.to_series() - noaa_data[\"water_level\"])\n",
    "        error_col.append(error)\n",
    "        rmse_col.append(rmse)\n",
    "        nrmse_col.append(nrmse)\n",
    "        \n",
    "\n",
    "        # plots\n",
    "        obs = aligned_data[station][\"observed\"]\n",
    "        mod = aligned_data[station][\"modeled\"]\n",
    "        \n",
    "        r2 = metrics.r2(mod, obs)\n",
    "        r2_col.append(r2)\n",
    "        \n",
    "        fig, ax = one2one(obs, mod)\n",
    "        ax.set_title(station.replace(\"_\", \" \"))\n",
    "        fn = (\n",
    "            figures\n",
    "            / f\"noaa_verified_scatter_water_level_{station}_{datum}_{case}.png\"\n",
    "        )\n",
    "        fig.savefig(fn, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(16, 9))\n",
    "        ax.set_title(station)\n",
    "        waterlevel.plot(ax=ax)\n",
    "        noaa_data.plot(ax=ax, lw=1, alpha=0.85)\n",
    "        ax.legend([\"Delft3D-FM\", \"NOAA verified\"])\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_title(f\"Water level ({station})\")\n",
    "        ax.set_ylabel(\"water level [m, NAVD88]\")\n",
    "        ax.set_xlim(left=noaa_data.index[0], right=noaa_data.index[-1])\n",
    "        fn = (\n",
    "            figures\n",
    "            / f\"noaa_verified_comparison_water_level_{station}_{datum}_{case}.png\"\n",
    "        )\n",
    "        fig.savefig(fn, bbox_inches=\"tight\", dpi=300)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_stats = pd.DataFrame(\n",
    "    np.stack([good_stations, nrmse_col, rmse_col, error_col, r2_col, xs, ys], axis=1),\n",
    "    columns=[\"station\", \"nrmse\", \"rmse_m\", \"bias\", \"r2\", \"lon\", \"lat\"],\n",
    ").astype(\n",
    "    {\n",
    "        \"station\": str,\n",
    "        \"nrmse\": float,\n",
    "        \"rmse_m\": float,\n",
    "        \"bias\": float,\n",
    "        \"r2\": float,\n",
    "        \"lon\": float,\n",
    "        \"lat\": float,\n",
    "    }\n",
    ")\n",
    "verified_stats_fn = output / f\"verified_stats_{case}.csv\"\n",
    "verified_stats.to_csv(verified_stats_fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized RMSE plot\n",
    "extent = [-93.5, -87, 28, 31]\n",
    "fig = plt.figure(figsize=(16, 6.5))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent(extent, ccrs.PlateCarree())\n",
    "ax.coastlines(resolution=\"10m\", color=\"black\", linewidth=1)\n",
    "im = ax.scatter(\n",
    "    verified_stats.lon,\n",
    "    verified_stats.lat,\n",
    "    s=80,\n",
    "    c=100 * verified_stats.nrmse,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    zorder=10,\n",
    "    cmap=\"jet\",\n",
    "    vmin=0,\n",
    "    vmax=30\n",
    ")\n",
    "cbar = plt.colorbar(im)\n",
    "if norm == \"tide\":\n",
    "    cbar.set_label(\"normalized rmse [% tidal range]\")\n",
    "else:\n",
    "    cbar.set_label(\"normalized rmse [%]\")\n",
    "\n",
    "for _, (station, _, _, _, _, lon, lat) in verified_stats.iterrows():\n",
    "    ax.text(\n",
    "        lon - 0.05,\n",
    "        lat - 0.05,\n",
    "        station.split(\"_\")[0],\n",
    "        horizontalalignment=\"right\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        zorder=101,\n",
    "    )\n",
    "    pass\n",
    "\n",
    "ax.set_title(\"Normalized RMSE of NOAA verified observations\")\n",
    "fn = figures / f\"nrmse_norm-{norm}_spatial_distribution_{datum}_{case}_verified.png\"\n",
    "fig.savefig(fn, bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error bar plot\n",
    "rc = {\"font.size\": 12}\n",
    "with plt.rc_context(rc=rc):\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    verified_stats.plot.bar(ax=ax, x=\"station\", y=\"nrmse\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"normalized RMSE [.]\")\n",
    "\n",
    "\n",
    "ax.set_title(\"Normalized RMSE for tidal prediction\")\n",
    "fn = figures / f\"nrmse_bar_plot_{datum}_{case}_verified.png\"\n",
    "fig.savefig(fn, bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE plot\n",
    "extent = [-93.5, -87, 28, 31]\n",
    "fig = plt.figure(figsize=(16, 6.5))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent(extent, ccrs.PlateCarree())\n",
    "ax.coastlines(resolution=\"10m\", color=\"black\", linewidth=1)\n",
    "im = ax.scatter(\n",
    "    verified_stats.lon,\n",
    "    verified_stats.lat,\n",
    "    s=80,\n",
    "    c=verified_stats.rmse_m,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    zorder=100,\n",
    "    cmap=\"jet\",\n",
    "    vmin=0,\n",
    ")\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.set_label(\"rmse [m]\")\n",
    "\n",
    "for _, (station, _, _, _, _, lon, lat) in verified_stats.iterrows():\n",
    "    ax.text(\n",
    "        lon - 0.05,\n",
    "        lat - 0.05,\n",
    "        station.split(\"_\")[0],\n",
    "        horizontalalignment=\"right\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        zorder=101,\n",
    "    )\n",
    "    pass\n",
    "\n",
    "ax.set_title(\"RMSE of tidal prediction\")\n",
    "fn = figures / f\"rmse_spatial_distribution_{datum}_{case}_verified.png\"\n",
    "fig.savefig(fn, bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error bar plot\n",
    "rc = {\"font.size\": 12}\n",
    "with plt.rc_context(rc=rc):\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    verified_stats.plot.bar(ax=ax, x=\"station\", y=\"rmse_m\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"RMSE [m]\")\n",
    "\n",
    "\n",
    "ax.set_title(\"RMSE for tidal prediction\")\n",
    "fn = figures / f\"rmse_bar_plot_{datum}_{case}_verified.png\"\n",
    "fig.savefig(fn, bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error bar plot bias\n",
    "rc = {\"font.size\": 12}\n",
    "stat = \"bias\"\n",
    "with plt.rc_context(rc=rc):\n",
    "    fig, ax = plt.subplots(figsize=(16, 9))\n",
    "    verified_stats.plot.bar(ax=ax, x=\"station\", y=f\"{stat}\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"bias [m]\")\n",
    "\n",
    "\n",
    "ax.set_title(\"Bias for tidal prediction\")\n",
    "fn = figures / f\"{stat}_bar_plot_{datum}_{case}_verified.png\"\n",
    "fig.savefig(fn, bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE plot\n",
    "extent = [-93.5, -87, 28, 31]\n",
    "fig = plt.figure(figsize=(16, 6.5))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent(extent, ccrs.PlateCarree())\n",
    "ax.coastlines(resolution=\"10m\", color=\"black\", linewidth=1)\n",
    "im = ax.scatter(\n",
    "    verified_stats.lon,\n",
    "    verified_stats.lat,\n",
    "    s=80,\n",
    "    c=verified_stats.bias,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    zorder=100,\n",
    "    cmap=\"jet\",\n",
    "    vmin=0,\n",
    ")\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.set_label(\"bias [m]\")\n",
    "\n",
    "for _, (station, _, _, _, _, lon, lat) in verified_stats.iterrows():\n",
    "    ax.text(\n",
    "        lon - 0.05,\n",
    "        lat - 0.05,\n",
    "        station.split(\"_\")[0],\n",
    "        horizontalalignment=\"right\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        zorder=101,\n",
    "    )\n",
    "    pass\n",
    "\n",
    "ax.set_title(\"Bias relative to verified data\")\n",
    "fn = figures / f\"bias_spatial_distribution_{datum}_{case}_verified.png\"\n",
    "fig.savefig(fn, bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## verified LMSL datum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = {\"font.size\": 16}\n",
    "nrmse_col = []\n",
    "rmse_col = []\n",
    "error_col = []\n",
    "r2_col = []\n",
    "xs = []\n",
    "ys = []\n",
    "good_stations = []\n",
    "datum = \"LMSL\"\n",
    "norm = \"tide\"\n",
    "aligned_data = {}\n",
    "stop_wl = -5\n",
    "\n",
    "with plt.rc_context(rc=rc):\n",
    "    for station in noaa_his_data.coords[\"station_name\"].values[:stop_wl]:\n",
    "        waterlevel = noaa_his_data[\"waterlevel\"].loc[t0:tf, station]\n",
    "        station = station.decode(\"ascii\")\n",
    "\n",
    "        # quick fix for error in station name\n",
    "        if station == \"ilots_Station_East_S.W._Pass\":\n",
    "            station = \"Pilots_Station_East_S.W._Pass\"\n",
    "\n",
    "        # exclude observation points outside domain\n",
    "        if np.isnan(waterlevel).all():\n",
    "            continue\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        # excludes NOAA which didn't have datum\n",
    "        noaa_data = noaa_measured_time_series_MSL[station].loc[t0:tf]\n",
    "        if not noaa_data[\"water_level\"].any():\n",
    "            continue\n",
    "\n",
    "        predicted_noaa_data = noaa_predicted_time_series_MSL[station]\n",
    "        predicted_noaa_data = noaa_predicted_time_series_MSL[station].loc[t0:tf]\n",
    "        \n",
    "        # manual shift to local MSL\n",
    "        eps = waterlevel.mean()\n",
    "        waterlevel = waterlevel - eps\n",
    "\n",
    "        # manual shift to local MSL\n",
    "        eps2 = noaa_data.mean()\n",
    "        noaa_data = noaa_data - eps2\n",
    "\n",
    "        # D3D results\n",
    "        xs.append(waterlevel[\"station_x_coordinate\"])\n",
    "        ys.append(waterlevel[\"station_y_coordinate\"])\n",
    "        good_stations.append(station)\n",
    "        \n",
    "        # align\n",
    "        df = pd.DataFrame(columns=[\"modeled\", \"observed\"], index=noaa_data.index)\n",
    "        df[\"modeled\"] = waterlevel.loc[noaa_data.index]\n",
    "        df[\"observed\"] = noaa_data[\"water_level\"]\n",
    "        aligned_data[station] = df\n",
    "\n",
    "        # stats\n",
    "        rmse = np.sqrt(\n",
    "            np.mean((waterlevel.to_series() - noaa_data[\"water_level\"]) ** 2)\n",
    "        )\n",
    "        \n",
    "        if norm == \"tide\":\n",
    "            nrmse = rmse / (\n",
    "                predicted_noaa_data[\"prediction\"].max() - predicted_noaa_data[\"prediction\"].min()\n",
    "            )\n",
    "        elif norm == \"water_level\":\n",
    "            nrmse = rmse / (noaa_data[\"water_level\"].max() - noaa_data[\"water_level\"].min())\n",
    "            \n",
    "        error = np.mean(waterlevel.to_series() - noaa_data[\"water_level\"])\n",
    "        error_col.append(error)\n",
    "        rmse_col.append(rmse)\n",
    "        nrmse_col.append(nrmse)\n",
    "        \n",
    "\n",
    "        # plots\n",
    "        obs = aligned_data[station][\"observed\"]\n",
    "        mod = aligned_data[station][\"modeled\"]\n",
    "        \n",
    "        r2 = metrics.r2(mod, obs)\n",
    "        r2_col.append(r2)\n",
    "        \n",
    "        fig, ax = one2one(obs, mod, quantity_str=\"water level [m, LMSL]\")\n",
    "        ax.set_title(station.replace(\"_\", \" \"))\n",
    "        fn = (\n",
    "            figures\n",
    "            / f\"noaa_verified_scatter_water_level_{station}_{datum}_{case}.png\"\n",
    "        )\n",
    "        fig.savefig(fn, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(16, 9))\n",
    "        ax.set_title(station)\n",
    "        waterlevel.plot(ax=ax)\n",
    "        noaa_data.plot(ax=ax, lw=1, alpha=0.85)\n",
    "        ax.legend([\"Delft3D-FM\", \"NOAA verified\"])\n",
    "        ax.set_xlabel(\"\")\n",
    "        ax.set_title(f\"Water level ({station})\")\n",
    "        ax.set_ylabel(\"water level [m, NAVD88]\")\n",
    "        ax.set_xlim(left=noaa_data.index[0], right=noaa_data.index[-1])\n",
    "        fn = (\n",
    "            figures\n",
    "            / f\"noaa_verified_comparison_water_level_{station}_{datum}_{case}.png\"\n",
    "        )\n",
    "        fig.savefig(fn, bbox_inches=\"tight\", dpi=300)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_LMSL_stats = pd.DataFrame(\n",
    "    np.stack([good_stations, nrmse_col, rmse_col, error_col, r2_col, xs, ys], axis=1),\n",
    "    columns=[\"station\", \"nrmse\", \"rmse_m\", \"bias\", \"r2\", \"lon\", \"lat\"],\n",
    ").astype(\n",
    "    {\n",
    "        \"station\": str,\n",
    "        \"nrmse\": float,\n",
    "        \"rmse_m\": float,\n",
    "        \"bias\": float,\n",
    "        \"r2\": float,\n",
    "        \"lon\": float,\n",
    "        \"lat\": float,\n",
    "    }\n",
    ")\n",
    "verified_LMSL_stats_fn = output / f\"verified_LSML_stats_{case}.csv\"\n",
    "verified_LMSL_stats.to_csv(verified_LMSL_stats_fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized RMSE plot\n",
    "extent = [-93.5, -87, 28, 31]\n",
    "fig = plt.figure(figsize=(16, 6.5))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent(extent, ccrs.PlateCarree())\n",
    "ax.coastlines(resolution=\"10m\", color=\"black\", linewidth=1)\n",
    "im = ax.scatter(\n",
    "    verified_LMSL_stats.lon,\n",
    "    verified_LMSL_stats.lat,\n",
    "    s=80,\n",
    "    c=100 * verified_LMSL_stats.nrmse,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    zorder=10,\n",
    "    cmap=\"jet\",\n",
    "    vmin=0,\n",
    "    vmax=50\n",
    ")\n",
    "cbar = plt.colorbar(im)\n",
    "if norm == \"tide\":\n",
    "    cbar.set_label(\"normalized rmse [% tidal range]\")\n",
    "else:\n",
    "    cbar.set_label(\"normalized rmse [%]\")\n",
    "\n",
    "for _, (station, _, _, _, _, lon, lat) in verified_LMSL_stats.iterrows():\n",
    "    ax.text(\n",
    "        lon - 0.05,\n",
    "        lat - 0.05,\n",
    "        station.split(\"_\")[0],\n",
    "        horizontalalignment=\"right\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        zorder=101,\n",
    "    )\n",
    "    pass\n",
    "\n",
    "ax.set_title(\"Normalized RMSE of NOAA verified observations\")\n",
    "fn = figures / f\"nrmse_norm-{norm}_spatial_distribution_{datum}_{case}_verified.png\"\n",
    "fig.savefig(fn, bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE plot\n",
    "extent = [-93.5, -87, 28, 31]\n",
    "fig = plt.figure(figsize=(16, 6.5))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent(extent, ccrs.PlateCarree())\n",
    "ax.coastlines(resolution=\"10m\", color=\"black\", linewidth=1)\n",
    "im = ax.scatter(\n",
    "    verified_LMSL_stats.lon,\n",
    "    verified_LMSL_stats.lat,\n",
    "    s=80,\n",
    "    c=verified_LMSL_stats.rmse_m,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    zorder=100,\n",
    "    cmap=\"jet\",\n",
    "    vmin=0,\n",
    ")\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.set_label(\"rmse [m]\")\n",
    "\n",
    "for _, (station, _, _, _, _, lon, lat) in verified_LMSL_stats.iterrows():\n",
    "    ax.text(\n",
    "        lon - 0.05,\n",
    "        lat - 0.05,\n",
    "        station.split(\"_\")[0],\n",
    "        horizontalalignment=\"right\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        zorder=101,\n",
    "    )\n",
    "    pass\n",
    "\n",
    "ax.set_title(\"Bias relative to verified data\")\n",
    "fn = figures / f\"rmse_spatial_distribution_{datum}_{case}_verified.png\"\n",
    "fig.savefig(fn, bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bias plot\n",
    "extent = [-93.5, -87, 28, 31]\n",
    "fig = plt.figure(figsize=(16, 6.5))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent(extent, ccrs.PlateCarree())\n",
    "ax.coastlines(resolution=\"10m\", color=\"black\", linewidth=1)\n",
    "im = ax.scatter(\n",
    "    verified_LMSL_stats.lon,\n",
    "    verified_LMSL_stats.lat,\n",
    "    s=80,\n",
    "    c=verified_LMSL_stats.bias,\n",
    "    transform=ccrs.PlateCarree(),\n",
    "    zorder=100,\n",
    "    cmap=\"jet\",\n",
    "    vmin=0,\n",
    ")\n",
    "cbar = plt.colorbar(im)\n",
    "cbar.set_label(\"bias [m]\")\n",
    "\n",
    "for _, (station, _, _, _, _, lon, lat) in verified_LMSL_stats.iterrows():\n",
    "    ax.text(\n",
    "        lon - 0.05,\n",
    "        lat - 0.05,\n",
    "        station.split(\"_\")[0],\n",
    "        horizontalalignment=\"right\",\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        zorder=101,\n",
    "    )\n",
    "    pass\n",
    "\n",
    "ax.set_title(\"Bias relative to verified data\")\n",
    "fn = figures / f\"bias_spatial_distribution_{datum}_{case}_verified.png\"\n",
    "fig.savefig(fn, bbox_inches=\"tight\", dpi=300)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
