{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from dfm_models.utils.analysis import get_modulus_angle, harmonic_analysis\n",
    "from dfm_models.utils.io import download_COOPs, download_nwis\n",
    "from dfm_models.utils.visualization import one2one, spatial_stat\n",
    "from VVUQ import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import geoviews as gv\n",
    "import geoviews.feature as gf\n",
    "import geoviews.tile_sources as gts\n",
    "\n",
    "from geoviews import opts\n",
    "\n",
    "from bokeh.models import HoverTool\n",
    "\n",
    "gv.extension(\"bokeh\", \"matplotlib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local functions\n",
    "# get rid of nans\n",
    "def check_nans(obs_wl):\n",
    "    if obs_wl.isna().sum() / len(obs_wl) > 0.05:\n",
    "        print(f\"{station_name} has more than 5% nans\")\n",
    "        return False\n",
    "    else:\n",
    "        obs_wl.fillna(method=\"ffill\", inplace=True)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARAMETERS ##\n",
    "# project files\n",
    "d3d = \"/mnt/c/Users/rdchlclj/Projects/MR_D3D_model/Delft3D/notebooks\"\n",
    "\n",
    "# NOAA COOPs\n",
    "tidal_stations_fn = (\n",
    "    \"/mnt/g/MR_D3D_model/ArcPro/MyProject/output data/tidal_constituents_stations.xlsx\"\n",
    ")\n",
    "\n",
    "# model data\n",
    "model_data = \"/mnt/g/MR_D3D_model\"\n",
    "case = \"p01\"\n",
    "case_name = \"p01_10sig_2019prod\"\n",
    "study = \"prod_2019\"\n",
    "model_output_fn = f\"{case}_merged_his.nc\"\n",
    "\n",
    "# analysis config\n",
    "# comparison dates\n",
    "begin_date = \"20190101\"\n",
    "end_date = \"20191231\"\n",
    "\n",
    "# tidal stations to drop\n",
    "coops_drop_stations = (\n",
    "    \"Pensacola\",\n",
    "    \"East Fowl River Bridge\",\n",
    "    \"Mobile State Docks\",\n",
    "    \"Chickasaw Creek\",\n",
    "    \"West Fowl River Bridge\",\n",
    "    \"Bayou La Batre Bridge\",\n",
    "    \"Grand Bay NERR, Mississippi Sound\",\n",
    "    \"Sabine Pass North\",\n",
    "    \"Texas Point, Sabine Pass\",\n",
    "    \"Weeks Bay, Mobile Bay\",\n",
    ")\n",
    "\n",
    "# determine whether to load observations\n",
    "loadObs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SET UP PATHS ##\n",
    "model_data = Path(model_data)\n",
    "\n",
    "d3d = Path(d3d)\n",
    "project = d3d / \"water_levels\"\n",
    "output = project / \"output\"\n",
    "obsOutput = output / \"observations\"\n",
    "input = project / \"input\"\n",
    "data = project / \"data\"\n",
    "\n",
    "# output\n",
    "case_output = output / case_name\n",
    "if not case_output.exists():\n",
    "    case_output.mkdir()\n",
    "\n",
    "analysis_output = case_output / \"water_level_error\"\n",
    "if not analysis_output.exists():\n",
    "    analysis_output.mkdir()\n",
    "\n",
    "# NOAA COOPs\n",
    "tidal_stations_fn = Path(tidal_stations_fn)\n",
    "tidal_stations_all = pd.read_excel(tidal_stations_fn, index_col=[0])\n",
    "tidal_stations = tidal_stations_all[~tidal_stations_all.name.isin(coops_drop_stations)]\n",
    "\n",
    "# USGS stations\n",
    "USGS_stations = pd.read_csv(input / \"USGS_stations.csv\")\n",
    "USGS_stations[\"station_code\"] = USGS_stations[\"station_code\"].str.strip(\"b'\")\n",
    "\n",
    "# model data\n",
    "model_output = model_data / f\"Delft3d/models/{study}/{case_name}\"\n",
    "his_fn = model_output / model_output_fn\n",
    "his_data = (\n",
    "    xr.open_dataset(his_fn)\n",
    "    .swap_dims({\"stations\": \"station_name\"})\n",
    "    .drop_vars([\"station_id\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate non-NOAA tide station output\n",
    "all_stations = his_data.coords[\"station_name\"].values\n",
    "NOAA_stations = [\"4\" not in str(t) for t in all_stations]  # NDBC station codes\n",
    "NOAA_stations = all_stations[NOAA_stations]\n",
    "noaa_his_data = his_data.sel(station_name=NOAA_stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Observations\n",
    "if not loadObs:\n",
    "\n",
    "    # NOAA observed time series data\n",
    "    datum = \"MSL\"\n",
    "    form = \"csv\"\n",
    "\n",
    "    noaa_wls = {}\n",
    "    noaa_pred = {}\n",
    "\n",
    "    for _, (station_id, station_name) in tidal_stations[[\"id\", \"name\"]].iterrows():\n",
    "\n",
    "        # meta data\n",
    "        station_code = station_name.replace(\" \", \"_\").replace(\",\", \"\")\n",
    "        NOAAData = download_COOPs(\n",
    "            \"hourly_height\", station_name, station_id, datum, begin_date, end_date\n",
    "        )\n",
    "\n",
    "        if check_nans(NOAAData):\n",
    "            noaa_wls[station_code] = NOAAData\n",
    "        \n",
    "        NOAAPred = download_COOPs(\n",
    "            \"predictions\", station_name, station_id, datum, begin_date, end_date\n",
    "        )\n",
    "\n",
    "        if check_nans(NOAAPred):\n",
    "            noaa_pred[station_code] = NOAAPred\n",
    "\n",
    "    # USGS stations\n",
    "    USGSWLs = {}\n",
    "\n",
    "    for _, (station_id, name) in USGS_stations[[\"station_code\", \"nickname\"]].iterrows():\n",
    "        USGSData = download_nwis(name, station_id, begin_date, end_date, data_code=65)\n",
    "\n",
    "        # no data\n",
    "        if type(USGSData) != pd.core.series.Series:\n",
    "            continue\n",
    "\n",
    "        # nans\n",
    "        if check_nans(USGSData):\n",
    "            USGSWLs[name] = USGSData\n",
    "            USGSWLs[name] -= USGSWLs[name].mean()\n",
    "            USGSWLs[name] *= 0.3048\n",
    "\n",
    "else:\n",
    "\n",
    "    try:\n",
    "        fn = obsOutput / f\"NOAAWLs-{begin_date}-{end_date}.pkl.gz\"\n",
    "        with open(fn, \"rb\") as f:\n",
    "            noaa_wls = pkl.load(f)\n",
    "        \n",
    "        fn = obsOutput / f\"NOAAPreds-{begin_date}-{end_date}.pkl.gz\"\n",
    "        with open(fn, \"rb\") as f:\n",
    "            noaa_pred = pkl.load(f)\n",
    "\n",
    "        fn = obsOutput / f\"USGSWLs-{begin_date}-{end_date}.pkl.gz\"\n",
    "        with open(fn, \"rb\") as f:\n",
    "            USGSWLs = pkl.load(f)\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Obsevations not available at:\\n\\t{fn}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = []\n",
    "nrmse_tide_col = []\n",
    "nrmse_col = []\n",
    "rmse_col = []\n",
    "r2_col = []\n",
    "xs = []\n",
    "ys = []\n",
    "stations = []\n",
    "\n",
    "## NOAA\n",
    "for station_name in noaa_wls.keys():\n",
    "\n",
    "    model_wl = (\n",
    "        his_data.sel(station_name=station_name.encode())[\"waterlevel\"]\n",
    "        .to_series()\n",
    "        .resample(\"1H\")\n",
    "        .mean()\n",
    "    )\n",
    "    obs_wl = noaa_wls[station_name]\n",
    "    pred_wl = noaa_pred[station_name]\n",
    "    \n",
    "    # regularize\n",
    "    tCommon = obs_wl.index.intersection(model_wl.index)\n",
    "    model_wl = model_wl.loc[tCommon]\n",
    "    obs_wl = obs_wl.loc[tCommon]\n",
    "\n",
    "    # demean\n",
    "    model_wl -= model_wl.mean()\n",
    "    obs_wl -= obs_wl.mean()\n",
    "\n",
    "    # D3D results\n",
    "    xs.append(his_data.sel(station_name=station_name.encode())[\"station_x_coordinate\"])\n",
    "    ys.append(his_data.sel(station_name=station_name.encode())[\"station_y_coordinate\"])\n",
    "    stations.append(station_name)\n",
    "\n",
    "    # stats\n",
    "    error = (model_wl - obs_wl).dropna()\n",
    "    rmse = np.sqrt(np.mean(error ** 2))\n",
    "    nrmse_tide = rmse / (pred_wl.max() - pred_wl.min())\n",
    "    nrmse = rmse / (obs_wl.max() - obs_wl.min())\n",
    "    r2 = metrics.r2(model_wl, obs_wl)\n",
    "\n",
    "    # store\n",
    "    rmse_col.append(rmse)\n",
    "    nrmse_col.append(nrmse)\n",
    "    nrmse_tide_col.append(nrmse_tide)\n",
    "    r2_col.append(r2)\n",
    "    number.append(len(error))\n",
    "\n",
    "    # figures\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    ax = one2one(obs_wl, model_wl, quantity_str=\"water level [m, MSL]\", ax=ax)\n",
    "    ax.set_title(station_name.replace(\"_\", \" \"))\n",
    "    fn = analysis_output / f\"{station_name}_noaa_verified_water_level_one2one.png\"\n",
    "    fig.savefig(fn, bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## USGS\n",
    "for _, (station_id, station_name) in USGS_stations[[\"station_code\", \"nickname\"]].iterrows():\n",
    "    \n",
    "    # no data\n",
    "    if type(USGSWLs[station_name]) != pd.core.series.Series:\n",
    "        continue\n",
    "        \n",
    "    # data\n",
    "    model_wl = (\n",
    "        his_data.sel(station_name=station_id.encode())[\"waterlevel\"]\n",
    "        .to_series()\n",
    "        .resample(\"1H\")\n",
    "        .mean()\n",
    "    )\n",
    "    obs_wl = USGSWLs[station_name].resample(\"1H\").mean().fillna(method=\"ffill\")\n",
    "\n",
    "    # regularize\n",
    "    tCommon = obs_wl.index.intersection(model_wl.index)\n",
    "    model_wl = model_wl.loc[tCommon]\n",
    "    obs_wl = obs_wl.loc[tCommon]\n",
    "\n",
    "    # demean\n",
    "    model_wl -= model_wl.mean()\n",
    "    obs_wl -= obs_wl.mean()\n",
    "\n",
    "    # D3D results\n",
    "    xs.append(his_data.sel(station_name=station_id.encode())[\"station_x_coordinate\"])\n",
    "    ys.append(his_data.sel(station_name=station_id.encode())[\"station_y_coordinate\"])\n",
    "    stations.append(station_name)\n",
    "\n",
    "    # stats\n",
    "    error = (model_wl - obs_wl).dropna()\n",
    "    rmse = np.sqrt(np.mean(error ** 2))\n",
    "    nrmse_tide = np.nan\n",
    "    nrmse = rmse / (obs_wl.max() - obs_wl.min())\n",
    "    r2 = metrics.r2(model_wl, obs_wl)\n",
    "\n",
    "    # store\n",
    "    rmse_col.append(rmse)\n",
    "    nrmse_col.append(nrmse)\n",
    "    nrmse_tide_col.append(nrmse_tide)\n",
    "    r2_col.append(r2)\n",
    "    number.append(len(error))\n",
    "\n",
    "    # figures\n",
    "    fig, ax = plt.subplots(figsize=(7, 7))\n",
    "    ax = one2one(obs_wl, model_wl, quantity_str=\"water level [m, MSL]\", ax=ax)\n",
    "    ax.set_title(station_name.replace(\"_\", \" \"))\n",
    "    fn = analysis_output / f\"{station_name}_USGS_verified_water_level_one2one.png\"\n",
    "    fig.savefig(fn, bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(\n",
    "    np.stack(\n",
    "        [stations, number, nrmse_col, nrmse_tide_col, rmse_col, r2_col, xs, ys,],\n",
    "        axis=1,\n",
    "    ),\n",
    "    columns=[\"station\", \"number\", \"nrmse\", \"nrmse_tide\", \"rmse_cm\", \"r2\", \"lon\", \"lat\"],\n",
    ").astype(\n",
    "    {\n",
    "        \"station\": str,\n",
    "        \"number\": int,\n",
    "        \"nrmse\": float,\n",
    "        \"nrmse_tide\": float,\n",
    "        \"rmse_cm\": float,\n",
    "        \"r2\": float,\n",
    "        \"lon\": float,\n",
    "        \"lat\": float,\n",
    "    }\n",
    ")\n",
    "stats[\"nrmse\"] *= 100\n",
    "stats[\"nrmse_tide\"] *= 100\n",
    "stats[\"rmse_cm\"] *= 100\n",
    "stats_fn = analysis_output / f\"{case}_water_level_error_stats.csv\"\n",
    "stats.to_csv(stats_fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "lon = hv.Dimension(\"lon\", label=\"Longitude [deg]\")\n",
    "lat = hv.Dimension(\"lat\", label=\"Latitude [deg]\")\n",
    "hv_stats = hv.Table(stats, kdims=[lon, lat])\n",
    "cols = stats.columns[2:-2].values\n",
    "clabels = {\n",
    "    \"nrmse\": \"normalized RMSE [% range]\",\n",
    "    \"nrmse_tide\": \"normalized RMSE [% tidal range]\",\n",
    "    \"rmse_cm\": \"RMSE [cm]\",\n",
    "    \"r2\": \"r-squared [.]\",\n",
    "}\n",
    "\n",
    "# hover tool\n",
    "tooltips = [\n",
    "    (\"Station\", \"@station\"),\n",
    "    (\"# obs.\", \"@number\"),\n",
    "    (\"Normalized RMSE [% range]\", \"@nrmse\"),\n",
    "    (\"Normalized RMSE [% tidal range]\", \"@nrmse_tide\"),\n",
    "    (\"RMSE [cm]\", \"@rmse_cm\"),\n",
    "    (\"r-squared\", \"@r2\"),\n",
    "]\n",
    "hover = HoverTool(tooltips=tooltips)\n",
    "\n",
    "# style\n",
    "psize = 10\n",
    "cst_lw = 1.25\n",
    "\n",
    "# Holoviews options\n",
    "cOpts = opts.LineContours(line_width=cst_lw)\n",
    "overOpts = opts.Overlay(aspect=6.5 / 3, responsive=True)\n",
    "\n",
    "# generate holomap\n",
    "holomap = hv.HoloMap(kdims=\"Statistic\")\n",
    "for col in cols:\n",
    "\n",
    "    clabel = clabels[col]  # colorbar text label\n",
    "\n",
    "    # options for points\n",
    "    pOpts = opts.Points(\n",
    "        size=psize,\n",
    "        color=col,\n",
    "        cmap=\"turbo\",\n",
    "        colorbar=True,\n",
    "        clabel=clabel,\n",
    "        tools=[hover],\n",
    "        clim=(0, hv_stats[col].max()),\n",
    "    )\n",
    "\n",
    "    # put together\n",
    "    overlay = (\n",
    "        gf.coastline(scale=\"10m\").opts(cOpts)\n",
    "        * gv.Points(hv_stats).opts(pOpts)\n",
    "        * gts.EsriImagery\n",
    "    )\n",
    "\n",
    "    # map\n",
    "    holomap[col] = overlay.opts(overOpts)\n",
    "\n",
    "# save output\n",
    "gv.save(holomap, analysis_output / f\"{case}_spatial_statistics.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store observations\n",
    "if not loadObs:\n",
    "    fn = obsOutput / f\"NOAAWLs-{begin_date}-{end_date}.pkl.gz\"\n",
    "    with open(fn, \"wb\") as f:\n",
    "        pkl.dump(noaa_wls, f)\n",
    "        \n",
    "    fn = obsOutput / f\"NOAAPreds-{begin_date}-{end_date}.pkl.gz\"\n",
    "    with open(fn, \"wb\") as f:\n",
    "        pkl.dump(noaa_pred, f)\n",
    "    \n",
    "    fn = obsOutput / f\"USGSWLs-{begin_date}-{end_date}.pkl.gz\"\n",
    "    with open(fn, \"wb\") as f:\n",
    "        pkl.dump(USGSWLs, f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
